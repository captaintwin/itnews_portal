Open source is giving you choices with your agent systems - Stack Overflow
Capture, share, & collaborate on knowledge internally.
Promote your product or service to developers and technologists.
Engage the world’s technology talent with your employer brand.
Open source is giving you choices with your agent systems
Ryan welcomes John Dickerson, CEO of Mozilla.ai, to talk about the evolving landscape of AI agents, the role of open source in keeping the tech ecosystem healthy, the challenges OS communities have faced with the rise of AI, and the implications of data privacy and user choice in the age of multi-agent AI systems.
is building the agent platform that helps organizations safely automate real work with AI agents.
Hello everyone, and welcome to the Stack Overflow Podcast, a place to talk all things software and technology. I'm your host, Ryan Donovan, and today we are talking about all those fun things with AI agents, interoperability, open-source, and how they can play nice with the rest of the ecosystem. My guest today is John Dickerson, who is CEO of Mozilla AI. So welcome to the show, John.
Hi Ryan, thanks for having me. Excited to chat for the next half an hour or so about all things open-source AI, and like you said, the agentic web.
Yeah. Well, we've hopefully got some good ears on this podcast. So, before we get started, we'd like to get to know our guests. Can you tell us a little bit about how you got into software and technology?
Like most people who are listening to this podcast, I'm one of those stories of, you know, 'hands on keyboard beforehand hands on a tv', that kind of thing. I started my professional career more on the academic side of things, and then transitioned into startups, which is becoming increasingly common. So, I ended up getting a PhD in what's called 'Market Design' at CMU in Pittsburgh, and market design is roughly technology at the intersection of, sort of, economics and computer science, machine learning, and optimization. So, you can think of this as like, 'how are matchings done on Uber? How is a recommendation done and priced on something like YouTube? How does Meta do a feed in a way that, you know, incentivizes good information to flow to the top, but also incentivizes advertisers to participate in the system?' And so on and so on. And so, as the internet sort of has been driven by these systems more and more, that sort of thinking has become more important. And then more recently, obviously with multi-agent systems, these agents themselves have their own little utility functions, and they have their own little emergent behavior, and so on. And these are problems actually that economists have been thinking about at a much smaller scale for a long time. And so, we'll see that sort of skillset, I think, become more important moving forward.
I mean, obviously everyone's talking about AI agents right now. It's a huge thing and I think the jump from going from LLMs and chat bots to agents is that interoperability, right? You're starting to talk to tools; you're starting to browse the web. How are you all thinking about this issue?
You know, just to get into the nitty gritty on definitions here, right? We have machine learning models, of which some are deep learning models, and then we have generative AI, which is sort of like LLMs, or think back to November 30th of 2022 when ChatGPT launched, and it was just tokens go in, tokens come out. No tool use, no browsing of the web, none of that kind of stuff. And then moving forward, we've now seen the sort of LLM title start to include tool use as table stakes for actually using an LLM. So people, when people refer to a model now, they typically actually refer to what I would call a system, which is something that can call out to the web, can call out to a vector database, maybe has some sort of knowledge graph behind the scenes, but isn't taking multiple steps to complete a task, right? It's that 'multiple steps to complete a task' that truly brings us into what you would call, like, modern agentic web browsing. And then if you have multiple agents, right? Maybe the most common paradigm here would be an orchestrator agent and a bunch of smaller ones who have particular tasks like browse, email, write code, et cetera– you start moving into multi-agent systems, and these are extremely complex. And so the way we're thinking about this is you can almost think about things as a slider between added stochasticity of these sort of very complex systems and also added power that comes with that, all the way back to traditional, sort of deterministic writing of code, or the use of a model that was trained once on data but is now, you know, running over and over again and less power. And so we wanna find, for different customers, or for different communities, where on that scale you should sit, such that you can accomplish a task, but that you're not like, banging your head against the wall because of this craziest stochastic complex system going off the rails.
Right. Our last developer survey found that the more people use AI, the less they trust it. And I think that's a sort of theme that's happening as people use it more and realize it's, like you said, the sarcastic difficulties it can bring.
Hard agree with that. And you know, as a technologist, if you give me two solutions and they both work the same, or they both have the same end result, which is a good end result, and one is something that I can trace line-by-line through and give it to my GRC, like risk and compliance on the enterprise side before deploying, and the other is a, you know, multi-agent system, which is going to do something different every single time I run it, I’m gonna choose the deterministic one. But it's not the case – I can't always create that deterministic solution very, very easily. And there's a lot of power in, sort of, the natural-language-to-complex-system push that multi-agent systems have now.
The folks who are doing those highly deterministic systems know it's a pile of conditionals, right? You can't always get every condition in that.
This is why I think we're seeing multi-agent systems really start to take off, is because we're now able to, even with an individual, right over a weekend for example, start to tackle some of these incredibly complex problems that involve needing to grok a bunch of different APIs and documentation and so on, and go out and gather information on the web; and you know, things that used to take a single human a long time to do, now we can get 98% of the way there very quickly. It's just understanding the 2% that isn't there, which becomes hard.
And grok as in understand and not either of the two AI systems.
So, with the rise of agents, and tool use, and sort of, interoperability, we're starting to see some standards emerge: A2A, MCP – I've heard of a couple others; I've heard these as sort of, like, compared to the founding of the web where you start getting some standards, but we've also seen, since the founding of web, not all of those standards have survived, right?
Absolutely. And you know, wearing my broader Mozilla hat – Mozilla has been a huge champion of open standards for the internet for going on 20 years now, and at mozilla.ai, we are becoming active in standards creation, as well. We're a much smaller team, but this is also a nascent space, right? So, you mentioned Model Context Protocol, or MCP, which came out of Anthropic but has now been donated to the Linux Foundation. A2A, sorry, has been donated to Linux Foundation. I'm not sure if MCP has yet, but they're both open, right? And they're both really standardizing some of the ways that models, or systems of models, can talk to traditional software, right? Like, you could have an MCP server for Slack or for email that standardizes the way that an MCP client on the LLM or LLM system side is able to gather information from that piece of software. That sounds like a traditional API on the internet. Like, I have a contract between a client and a server, and now I'm able to build with confidence because I know the way data's going to come back into my system is going to look like X, or Y, or Z. MCP, you know, it's imperfect. A2A, another one – this is an agent-to-agent protocol that came out of Google initially, and that one, I know, is now part of the Linux Foundation. It's had support from Cisco Agency, I think a bunch of other sort of big companies, as well. And this is again, sort of standardizing the way the different agents can talk to each other, which will again, become increasingly important as the web shifts from just humans interacting with it, to humans who have agents, to just pure agent interactions. Sometimes those agents need to have their own language, basically their own way of communicating with each other. You know, we call Google and we call Meta 'frenemies' to open-source, in the sense that, you know, they do support the open-source ecosystem, but it's not out of the goodness of their heart. So, they're doing this for a reason, right? But it's great to see.
I've definitely heard of the big hyperscalers being, you know, kind of taking over projects as they get in there, and they start having their people work on it.
Again, blessing and a curse, right? I mean, you know, Google can allocate 10 Mozilla.ai's-worth of headcount without blinking their eye.
The interoperability, the standards, the sort of like, 'playing nice' with the rest of the web has seemed to be a pretty important development. I've heard of a lot of people complaining about the increased traffic spikes from AI agents and bots. If you discover an API in the internet, can you use it?
I have, sort of, two minds here. I have a lot of sympathy for website owners who are getting hit by these bots, and I know you've had discussants on this podcast as well, talking about, you know, 'what does data creation look like in a world where agents are just taking any sort of new data that you have and moving that off of your platform so you can't monetize it? Are you incentivized even to create new information? What does the economy look like at that point?' Et cetera, et cetera. I also have a lot of empathy for open-source code maintainers, right? Where, it's now very easy to take, as input, an entire open-source code base, ask in natural language, write a PR that does X, Y, or Z, and then just spam an open-source code base with, you know, reasonably legitimate but imperfect PRs. And we're seeing this, sort of, across the board in the open-source world, as well. And so, like, that's a bit of a traffic spike as well, caused, you know, from the goodness of people's hearts. But it's something that I'm curious about what that's gonna do to the open-source community, right? It's going to, you know – every morning you wake up as a maintainer and you have 100 new PRs that somebody spent 30 seconds on, and you're gonna have to spend an hour on each time. Like, what does that do to incentives at that point, as well? Yeah.
That's the thing, the question that every community, whether it's an open-source or a forum on the Internet, is gonna have to answer. You know, we're encountering that now at Stack Overflow, where it's like, how do we keep getting people to come answer new questions? And it's something we are actively working on every day.
Yeah, I don't have a clear answer to that, but I think the economics of the internet—and I mean economics in terms of dollars and cents, but also economics in terms, you know, a lot of internet content is created out of the goodness of your heart to support a community and not to make money—you're going to feel used if all of that goes into, you know, a black box opening AI or anthropic model. Nobody directs any traffic to your site.
People hear 'Mozilla', they mostly think 'Firefox,' right? I know there's the Mozilla Foundation, and a lot of technologies under there. How does the, sort of, agentic thinking and AI that we're talking about here– how does that fit into Mozilla's sort of 'game plan' and mission?
Yeah, so the way I view Mozilla is we're supporting access to information, to knowledge, and to people. We're democratizing that access. We're giving clear ownership of your own data, and that can be via Firefox's privacy guarantees, or that can be via agentic browsing – you know, making sure that we're not, you know, leaking a bunch of data to some other system via our agentic systems, as well. So, at the end of the day, the browser is just one way to access information in the world, agentic browsing is another way to access information in the world, social networks are another way to access information in the world, and so on. So, you know, Mozilla – we've had a lot of success, obviously with Firefox, and the Firefox community is absolutely incredible, but that's just one way to support the broader Mozilla, sort of, 'manifesto' and mission of democratizing access to the world.
You've mentioned the Firefox privacy guarantees – there's a lot of AI companies that are talking about getting their own browsers and even getting their own social networks, and it feels a little bit like, 'oh, this is another way to harvest data.' How do you think about that, and how can we, sort of, avoid just being a data farms?
We'd like to say, at Mozilla.ai, that we support choice. So, we love to have users choose the ability to have different models in their systems, closed or open, different guardrails, different agentic systems, and so on. I also like– as a person, and also speaking for Mozilla, we support browser competition and browser choice, as well. And so, that's choice within the browser of X, and Y, and Z technologies, you know, your mail client, and so on. But that's also choice of browser, right? I don't want to be in a world where there's only Firefox. I want there to be, you know, 100 different browsers competing and trying out new things. And in that sense, I am excited that we're seeing a lot of activity in the browser space. The flip side is, you are right. I mean, large companies are building browsers, in part, to train agentic browsing systems, but also to scoop up data, right? And the way you– you know, OpenAI has an internal browser, Anthropic, I believe used a fork of Brave for some of their agentic stuff. The way you train agents is, I mean– you have to have a simulator, but you also have data. So, at the end of the day, like, you should go into those systems with your eyes open, just like anything else on the web, right? Most things that are free are not, you know, the same. Like, you're the product, right?
You're the product. If you're not paying for it, you're the product, yeah. I wanna touch on something – you have the answer to this one: you mentioned the choice in browsers... how deep does that choice go? Because I know a lot of browsers are sort of forks of Chromium, or they're all building on the same, like, ECMO script engines.
Yeah. So, I mean, we have the three, and this is, again, getting a little out of my wheelhouse. I'm not a browser guy; I'm an AI guy. But you know, I have used Firefox for 20+ years at this point. So, you know, we have the three major bases, right? We have the one that Mozilla maintains, we have the one that came outta Google, and then we have the one that Apple maintains. And even being in a world where only two of those existed, would be very bad. But I would love to see more. It's just, it is very, very hard to put together a rendering engine that is powerful enough to handle– you mentioned standards, right? HTML has a bunch of standards, but you've seen HTML. Nobody's writing standards-compliant HTML. So.
I mean, at least we're not at the stage where specific browsers have their own JavaScript, you know?
I do hope that doesn't happen, and it is really heartening to see the large players interact with standards for the new web. And you know, we are gonna see TypeScript become more and more important in the machine learning world because of agentic browsing, right? And so, people tend to think machine learning is only Python, but it's like, it's not only Python, right? If you go onto a Vercel or something like that, I'm guessing most of Vercel's deployed apps are in TypeScript first and not in Python, right? I'm hoping we don't see, like, the Chrome-type script for agents, or whatever.
I hope we don't see it again. I know that early Internet Explorer did have its own JavaScript.
It's always a blessing and a curse, right? We do want people to be trying things out. It's the same thing with regulation, like government regulation, right? If you regulate too early, then you don't have an opportunity to explore different options. You don't have an opportunity to find a better solution to a problem that you have, but if you don't, there are bad things that happen too.
We've been talking about a good amount of 'bad' open-source. We're big fans of open-source here. We've been seeing a lot of open-source LLMs. Do you think those are a good thing for the world?
We can hop into the brief discussion that always needs to happen, which is 'open-source' versus 'open weights.' And most of the models, especially the very powerful models that are coming out, are what are called 'open weight,' which is to say there's a mysterious set of training data that you don't know about, and there's some training code, and there's data filtration, and data ordering, and all this kind of stuff that happened behind the scenes to actually train the model. But you don't get access to that. You get access to the weights – the final train model, or maybe a set of what are called 'checkpoints,' which are like different snapshots of the model during the training process. Maybe, you know, before post-training, and then after some sort of alignment, or whatever. And that's different than open-source, which would say something like, 'I give you – here's how I got the data. Here's how I did data filtration. Here's my training code. Here's exactly when I cut things off. Here are the eval metrics for that during the training process. And also, here are the weights.' And there are some great companies out there – one out here in Seattle called The Allen Institute, or locally called AI2, which puts out true open-source models. It's just, it's hard, right? Monetizing pure open-source models is just as difficult as monetizing open-source software has been forever, which is that if you give everybody everything, then you don't have a moat necessarily. And you're basically putting together a community, or you're adding add-ons, things like that. And that's something that we'll struggle with, as well, and was love at AI, it's something AI2 does. So, most companies put out open weight models, right? The llama herd that came out of Meta is open weight. The Gemma set of models, which you can think of kind of like as the 'baby Google Gemini models' that are coming out of Google are open weight. DeepSeek from China– the R1 and the distilled models are open weight. Quam coming out of the Chinese 'Mag 7', effectively open weight, and so on. You know, as an open-source guy, I would rather have access to everything, but I'd much rather have access to an open weight model than nothing. And so I'm very, very happy these are coming out. And you've mentioned, you know, 'is it good or is it bad for the open weight models to exist?' And before we started recording, I'd mentioned, you know, any sort of technology, especially dual use technology, right? Like, this can be used in defense and offense, as well. But like, any technology can be used for bad. And it's the same argument that you would have around encryption, which is, 'would you rather live in a world where everything was unencrypted, or everything was able to be decrypted by a central government?' Something like that. And yeah, bad things happen on the internet because of encryption, right? But like, a person could engage in illicit activities, and it would be harder to understand that those were going on because of encryption. But there's so much good that comes outta encryption as well, that I would – if I had to choose zero or one, I would choose one. We should be allowed to encrypt. And the same discussions are going to happen – already happening with open-source AI around sovereign AI as well, but also like, if I open-source a model, is my nation state enemy going to be able to build on that and build something bad? It's possible.
That is the question with every technology, right? Like, you have a hammer. You could build a house with it or you could, you know, crack skulls.
I think that's absolutely right, yeah. And so, we need norms. We need, you know– when the time is right, we'll need to have some sort of regulatory landscape around this. You're seeing the US start to do this in a very different way, obviously, than the EU is doing this in a very different way than Canada is doing this in a very different way than the Middle East is doing this, et cetera, et cetera. We're very early days there.
You talked about sovereign AI. I think we've touched on that on this program before. It's an interesting concept. Do you think that countries should have their own AI systems?
It's hard because not every country can create at the level of a US, or a China, or the EU, if the EU would actually start operating as one entity, or the Middle East trying to be somebody who plays with everybody, right? You can only have so many of these coalitions pop up before you just simply don't have the capital expenditure to create something that, you know, looks like a frontier model, right? I was in the UK recently and one of the party lines that they have is—if you look at their R&D spend for the UK on tech, it's half of what Amazon spent. Like, so, one company – half of what they spend on R&D is already a nation state. So, you asked about, you know, is it good or bad to have sovereign AI? This is more like– it doesn't even matter for a lot of these countries. Like, you just can't be on the same stage. And I didn't even mention hardware here, right? Like, ASML, TSMC, and Nvidia that stacked together – you have to play well with at least the countries that run those if you even wanna play ball at all in this space. You know, there's the good, bad question, and then there's also like, the 'you should wake up to whether or not your country even can do this.' Now, on the good-bad side of things, this is a very powerful technology and I do think we shouldn't live in a world where only one country controls everything. In general, I don't believe in a hegemon for anything in technology, and I understand why governments are concerned about this because, you know, you can be cut off from hardware and then you will not be able to train this. So, if you are cut off from hardware and there's no open sourcing of models, then you potentially could be left out of this. Yeah.
You know, another problem we've seen is that the AI models, especially when they don't show their training, or whatever else is going in there, they can sort of control the information flows coming out. We've seen models, sort of, 'disappear' bits of history, or force certain topics into prominence.
That's absolutely right. And you know, this is one of many reasons why we believe in the open web, and we believe in open-source, and why we believe in trying to be as unbiased as possible with access to information. But you're absolutely right. Like, I can broadly call 'post-training', but if you've heard of 'supervised fine tuning,' or if you've heard of, you know, 'preference optimization,' or the things that go into reasoning models, which we don't have to hop into here; but like, the thing that happens after you do pre-training, which is like, you scoot a model in a particular direction to speak potentially in a particular way. Some of that is good, right? If I, for example, am running a large enterprise and I have a particular set of values that I want to espouse in my internal teams channels, or whatever, via my chat bot, I'm totally fine, you know, fine tuning away language, right? Like, companies have their own cultures, and so on. But your statement about, you know, 'can I erase information by removing it from the training data, or from aligning away from it?' Absolutely, 100%. And this is one of the reasons why we need open-source.
Theoretically, if open-source open weights models were to disappear—if they were like, 'hey, these are danger,' and all governments came down and said, 'you can't do this anymore,' what do you think would be the effect on the software ecosystem?
Yeah, I mean there are different ways that that would occur, right? One would be something like, there's a trillion-parameter model that is out there already, and as you know, you can't erase anything from the internet ever. So like, that's not going away. But like, I need hardware to be able to run this thing. So, you could start doing restrictions on the amount of hardware that you have, right? You already see this happening with the US doing expert restrictions on the video hardware, for example. And, you know, I wanna espouse an opinion on that, but it is a thing that happens. It's a lever that you could play around with. The other would be putting, like, the Biden executive order during the Biden administration put a limit on the amount of training that you could do on the size of the model, as well. I think it was like 10 to the 26 parameters, or something like flops used to train, or something. Like, those kinds of things are not going to age well. Those numbers are never gonna age well. But I could have a restriction like that that's put on. One thing I think you're gonna see happening, regardless of this happening, frankly, is with multi-agent systems, you're starting to see specialization of models happen again. And specialization allows me to have smaller models basically, right? And so, I can have, for my TypeScript coding agents that I use for my, whatever, medical website development bot, right? Something very specific. I can have a very small model that does very well for that specific task. The issue here is that these small models are often trained via a process that involves something called 'distillation,' which says, 'I look at a really big model and I ask it really smart questions, and it answers in a really smart way because it's a really smart model,' and then I try and get my really small model to answer in a very similar way. And if I don't have access to that really big model, either it's an open-source model that's there and I'm able to run it, or if this becomes somehow illegal or harder to do, then I have to hit out to an API, and that API is gonna have all the problems that you talked about, which is that I can have this API access to a model, I can have it erase information, right? I can have it respond in particular ways. That would be bad, right? I then would have trouble doing a really good job at training that tiny model.
Those sort of distillations are, you know, if you're using a large commercial model, it's often against their terms of service, right? You're opening yourself up for a liability.
Sometimes it is, right? You know, there's a lot of rumors around DeepSeek doing this with open AI, and sometimes it isn't, right? If you look at like, the llama herd that has come out, you know, the smaller llama models were trained via distillation and, you know, people trained via distillation on a large llama herd. I think that's fine up to, I haven't checked recently, but up to like, 7 million users or whatever their thing says that says like, 'you can't be Google and use this.' Constraints do beget creativity, as well, right? I think you see this with like, the creation of Linux, right? There was a Linux moment at one point, and that's because there was a lot of closed ecosystem out there, and you know, Unix was not playing ball nicely with the rest of the world, and so on. I could see, and again, I don't want this to happen, I don't want open weight models to go away, but in the event that we lived in the constrained world, we'll see creative solutions popping up in random places, so, yeah.
Right. What did you think, there'd be a little 'underground distilled models' floating around, passed hand-to-hand on USB keys?
I mean, you know the internet, right? I'm sure that would happen. There is a lot of effort right now in federated learning, in distributed training, et cetera, et cetera, and like the Internet's gonna do what the Internet's gonna do, regardless. Yeah.
Yeah. You talked about the creative restrictions. One of the places I wonder if we're gonna get, sort of, the most creative stuff is the quantized model space, like on mobile devices, or edge devices. Like, I was a Commodore 64 user back in the day, and the Demoscene there was amazing – what they could fit to 64K memory...
Oh man, Demoscene's so cool. Yeah. I need to go to Germany again. Demoscene's pretty alive still in Germany. It's pretty cool stuff. Yeah. So, quantization– I think it's very important. You mentioned Edge, as well. Edge is extremely important right now. So, at Mozilla.ai we work with a company called Open MRS—Open Medical Record System—and they operate with about 22 million different patients, primarily in the developing world. And the compute that they have is, you know, maybe you're gonna call out to like, a local like HIPAA-compliant AWS, or something like that. But often you don't have access to that. You have a very old computer, or a very old, you know, a Pixel6 or something like that – a phone that's okay, but not like super recent that needs to run something on Device, on Edge. It's gonna be a very tiny model. It's gonna be quantized, and so on. We already are seeing, but I think we're gonna see more, really cool work on like, exactly like, optimizing for a particular task. Exactly where you're quantizing, where you're dropping bits and things like that. I know there's an internal team at Google doing a lot of this. I would guess that there are teams at Meta, and Microsoft, and so on doing this, as well. But in the open world, I think that's gonna be a really powerful, because in much the same way that I was talking about these tiny, hyper specific small language models that are trained to do a very specific task, quantization is just part of that, right? It's part of the parameter space for what you can do to optimize, and harder to do.
I wonder if you have other examples of folks in the wild that you're working with that are doing interesting things with the open AI ecosystem?
In general, I mean, when you talk to enterprises even, enterprises love open-source software because you can avoid vendor lock-in, you can see what you're actually getting, you can make edits to it, and so on. That same sort of pitch is actually resonating with enterprises now, and I don't have the graph here, but Wiz, which is that large is Israeli security company, put out a research report in earlier this year—so we're recording this in 2025, so this would've been like January, February, 2025—where they looked at a bunch of their customers hosted AI solutions, and unsurprisingly, the OpenAI SDK was like, 'two thirds of our hosted solutions used the OpenAI SDK fine, but if you look at the top 10, eight of them were open-source, or open-source adjacent AI technologies.' So like, Hugging Face was there, PyTorch was there, Onyx was there. Llama file actually, which was one that AI owns, was there. LangChain, which is what I would call open-source adjacent—they have some open-source and then they also sow a product on top of that—was there. And so, if you look at the 10, 80% of them were open-source or open-source-friendly, and then if you go down—I think they listed like 35 of them—it was like 60% of them were open-source. You know, you see a lot of noise around the anthropics and the AIs of the world, but when it comes to actually like, you know, Brass Tax and deploying things, people love open-source, open-source AI, for the same reasons that they love open-source software. We're just excited about the agentic web taking off. We're excited about the power of agents, but you know, anybody who's promising you the moon [or that] things aren't going to screw up, you know– if we're gonna be able to, in 30 seconds, be able to solve all your problems, like, you're gonna be in for a tough ride there. And so, you know, there's a lot of exciting work to be done in evaluation specifically, and standard setting around evaluation, actually. So, there's something called Traces, which are kind of the– think of this as the digital exhaust of agents, as they browse around the internet. There's really no good standard for a single agent or multi-agent tracing, right now. And that will be incredibly important moving forward. And so, you know, for those who are listening to this podcast, if that kind of stuff is interesting to you, like, definitely reach out to us.
Well, ladies and gentlemen, it's that time of the show where we shout out somebody who came on to stack overload, dropped some knowledge, shared some curiosity, and earned themselves a badge. Today we're shouting out a populous badge winner – somebody who came to a question and dropped an answer that was so good, it outscored the accepted answer. So, congrats to Philipp Merkle for dropping an answer on 'How to set the -Xmx when start running a jar file?' If you're curious about that, we'll have the answer in the show notes. I'm Ryan Donovan. I edit the blog and host the podcast here at Stack Overflow. If you have questions, concerns, or topics we should talk about, please email me at podcast@stackoverflow.com. And if you wanna reach out to me directly, you can find me on LinkedIn.
I'm John Dickerson, CEO of Mozilla AI, and if you just search John P. Dickerson anywhere on the internet, you'll probably come across me. I'm the only one of those. But if you'd like to reach out directly, I'm J-O-H-N, john@mozilla.ai.
All right everyone, thanks for listening, and we'll talk to you next time.
Get The Stack Overflow Podcast at your favorite listening service.
AI agents will succeed because one tool is better than ten
From multilingual semantic search to virtual assistants at Bosch Digital
Craft and quality beat speed and scale, with or without agents
Data licensing offering to build and improve AI tools and models.