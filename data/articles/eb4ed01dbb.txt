OpenAI says over a million people talk to ChatGPT about suicide weekly | TechCrunch
OpenAI says over a million people talk to ChatGPT about suicide weekly
on Monday illustrating how many of ChatGPT’s users are struggling with mental health issues and talking to the AI chatbot about it. The company says that 0.15% of ChatGPT’s active users in a given week have “conversations that include explicit indicators of potential suicidal planning or intent.” Given that ChatGPT has more than 800 million weekly active users, that translates to more than a million people a week.
The company says a similar percentage of users show “heightened levels of emotional attachment to ChatGPT,” and that hundreds of thousands of people show signs of psychosis or mania in their weekly conversations with the AI chatbot.
OpenAI says these types of conversations in ChatGPT are “extremely rare,” and thus difficult to measure. That said, the company estimates these issues affect hundreds of thousands of people every week.
OpenAI shared the information as part of a broader announcement about its recent efforts to improve how models respond to users with mental health issues. The company claims its latest work on ChatGPT involved consulting with more than 170 mental health experts. OpenAI says these clinicians observed that the latest version of ChatGPT “responds more appropriately and consistently than earlier versions.”
In recent months, several stories have shed light on how AI chatbots can
struggling with mental health challenges. Researchers have previously found that
AI chatbots can lead some users down delusional rabbit holes
, largely by reinforcing dangerous beliefs through sycophantic behavior.
Addressing mental health concerns in ChatGPT is quickly becoming an existential issue for OpenAI. The company is currently being
who confided his suicidal thoughts to ChatGPT in the weeks leading up to his suicide. State attorneys general from California and Delaware — which could block the company’s planned restructuring — have also warned OpenAI that it
Earlier this month, OpenAI CEO Sam Altman claimed in a
that the company has “been able to mitigate the serious mental health issues” in ChatGPT, though he did not provide specifics. The data shared on Monday appears to be evidence for that claim, though it raises broader issues about how widespread the problem is. Nevertheless, Altman said OpenAI would be relaxing some restrictions, even allowing adult users to start
Google Cloud, Netflix, Microsoft, Box, Phia, a16z, ElevenLabs, Wayve, Hugging Face, Elad Gil, Vinod Khosla — some of the 250+ heavy hitters leading 200+ sessions designed to deliver the insights that fuel startup growth and sharpen your edge. And don’t miss 300+ showcasing startups in all sectors.
Bring a +1 and save 60% on their pass, or get your pass by Oct 27 to save up to $444.
Google Cloud, Netflix, Microsoft, Box, Phia, a16z, ElevenLabs, Wayve, Hugging Face, Elad Gil, Vinod Khosla — some of the 250+ heavy hitters leading 200+ sessions designed to deliver the insights that fuel startup growth and sharpen your edge. And don’t miss 300+ showcasing startups in all sectors. Bring a +1 and save 60% on their pass, or get your pass by Oct 27 to save up to $444.
In the Monday announcement, OpenAI claims the recently updated version of GPT-5 responds with “desirable responses” to mental health issues roughly 65% more than the previous version. On an evaluation testing AI responses around suicidal conversations, OpenAI says its new GPT-5 model is 91% compliant with the company’s desired behaviors, compared to 77% for the previous GPT‑5 model.
The company also says its latest version of GPT-5 also holds up to OpenAI’s safeguards better in long conversations. OpenAI has previously flagged that its safeguards were less effective in long conversations.
to measure some of the most serious mental health challenges facing ChatGPT users. The company says its baseline safety testing for AI models will now include benchmarks for emotional reliance and non-suicidal mental health emergencies.
of children who use ChatGPT. The company says it’s building an age prediction system to automatically detect children using ChatGPT, and impose a stricter set of safeguards.
Still, it’s unclear how persistent the mental health challenges around ChatGPT will be. While GPT-5 seems to be an improvement over previous AI models in terms of safety, there still seems to be a slice of ChatGPT’s responses that OpenAI deems “undesirable.” OpenAI also still makes its older and less-safe AI models, including GPT-4o, available for millions of its paying subscribers.
If you or someone you know needs help, call 1-800-273-8255 for the
. You can also text HOME to 741-741 for free; text 988; or get 24-hour support from the
Maxwell Zeff is a senior reporter at TechCrunch specializing in AI. Previously with Gizmodo, Bloomberg, and MSNBC, Zeff has covered the rise of AI and the Silicon Valley Bank crisis. He is based in San Francisco. When not reporting, he can be found hiking, biking, and exploring the Bay Area’s food scene.
You can contact or verify outreach from Maxwell by emailing
Have a +1 you’d like to bring to Disrupt? Bring them along and save 60% on their pass. Or get up to 30% off on group passes.
Join 10,000 founders, investors, and tech leaders — and save when you come together to the tech epicenter of the year.
India, the market BlaBlaCar once walked away from, is now its biggest
Rivian will pay $250M to settle lawsuit over R1 price hike
20-year-old dropouts built AI notetaker Turbo AI and grew it to 5 million users
Instagram users can now use Meta AI editing tools directly in IG Stories
Two days after OpenAI’s Atlas, Microsoft relaunches a nearly identical AI browser
Amazon will buy thousands of pedal-assist cargo vehicles from Rivian spinoff Also
Rivian spinoff Also reveals a high-end modular e-bike for $4,500