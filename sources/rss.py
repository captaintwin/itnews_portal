import feedparser
from datetime import datetime, timedelta, timezone
from core.logger import log


def fetch_rss(feed_url: str, limit: int = 20, hours_back: int = 24):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏ –∏–∑ RSS-–ª–µ–Ω—Ç—ã, —Ñ–∏–ª—å—Ç—Ä—É–µ—Ç –ø–æ –¥–∞—Ç–µ (–∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ X —á–∞—Å–æ–≤)
    –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π.
    """
    log.info(f"Fetching RSS: {feed_url}")
    feed = feedparser.parse(feed_url)
    articles = []
    cutoff = datetime.now(timezone.utc) - timedelta(hours=hours_back)

    for entry in feed.entries[:limit]:
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞—Ç—É –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
        published_parsed = getattr(entry, "published_parsed", None)
        if published_parsed:
            pub_date = datetime(*published_parsed[:6], tzinfo=timezone.utc)
        else:
            pub_date = None

        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ç–∞—Ä—ã–µ —Å—Ç–∞—Ç—å–∏
        if pub_date and pub_date < cutoff:
            continue

        # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ —Å—Ç–∞—Ç—å–µ
        article = {
            "title": getattr(entry, "title", "").strip(),
            "url": getattr(entry, "link", "").strip(),
            "summary": getattr(entry, "summary", "")[:500].strip(),
            "published_at": pub_date.isoformat() if pub_date else "",
            "source": feed.feed.get("title", feed_url),
        }
        articles.append(article)

    log.info(f"üì° {feed_url} ‚Üí –Ω–∞–π–¥–µ–Ω–æ {len(articles)} –Ω–æ–≤–æ—Å—Ç–µ–π –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ {hours_back} —á.")
    return articles
