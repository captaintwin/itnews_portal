[
  {
    "source": "TechCrunch",
    "url": "https://techcrunch.com/feed/",
    "coverage": 88.9,
    "example": {
      "id": 418966650,
      "title": "Big tech is paying for Trump’s White House ballroom",
      "description": "Trump's $250 million White House ballroom will be funded in part by big tech companies like Amazon, Apple, Google, Meta, and Microsoft.",
      "content": "Trump's $250 million White House ballroom will be funded in part by big tech companies like Amazon, Apple, Google, Meta, and Microsoft.",
      "url": "https://techcrunch.com/2025/10/23/big-tech-is-paying-for-trumps-white-house-ballroom/",
      "image": "",
      "publishedAt": "Fri, 24 Oct 2025 02:54:46 +0000",
      "lang": "en",
      "source": {
        "id": "techcrunch.com",
        "name": "TechCrunch",
        "url": "https://techcrunch.com/feed/",
        "country": ""
      }
    }
  },
  {
    "source": "The Verge",
    "url": "https://www.theverge.com/rss/index.xml",
    "coverage": 88.9,
    "example": {
      "id": 4416391252,
      "title": "Verizon launches Lite home internet for people in limited coverage areas",
      "description": "Verizon is launching a new “Lite” home internet plan for people in areas previously not covered by its fiber and 5G internet. The new plan offers download speeds of up to 25Mbps, but it costs as much as $60 per month without any discounts. Verizon says its Lite plan is best for “light” internet usage [&#8230;]",
      "content": "<figure>\n\n<img alt=\"\" src=\"https://platform.theverge.com/wp-content/uploads/sites/2/2025/05/STK066_VERIZON_B.jpg?quality=90&#038;strip=all&#038;crop=0,0,100,100\" />\n\t<figcaption>\n\t\t</figcaption>\n</figure>\n<p class=\"has-text-align-none\">Verizon is launching a <a href=\"https://www.verizon.com/about/news/verizon-expands-home-internet-more-customers-new-lite-plan\">new “Lite” home internet plan</a> for people in areas previously not covered by its fiber and 5G internet. The new plan offers download speeds of up to 25Mbps, but it costs as much as $60 per month without any discounts.</p>\n\n<p class=\"has-text-align-none\">Verizon says its Lite plan is best for “light” internet usage in homes limited to “older, less reliable options like DSL or satellite.” Customers who already use Verizon for their postpaid mobile phone service will<strong> </strong>benefit the most from the heavy discounts. You’ll save $15 / month when the service is combined with a mobile plan.</p>\n\n<p class=\"has-text-align-none\">It’s also offering a $10 monthly discount for paperless billing and autopay, along with an <a href=\"https://www.verizon.com/about/news/legal/vih-disclaimers\">additional $10 discount available</a> for three years if mobile phone customers sign up before December 31st. All these discounts bring the price down to $25 per month.</p>\n<img alt=\"\" src=\"https://platform.theverge.com/wp-content/uploads/sites/2/2025/10/verizon-home-internet-lite.png?quality=90&#038;strip=all&#038;crop=0,0,100,100\" title=\"\" />\n<p class=\"has-text-align-none\">Though Verizon’s Lite plan may be ultra-cheap if you’re able to take advantage of the price cuts, it’s quite slow when compared to other budget internet plans. <a href=\"https://www.t-mobile.com/home-internet/plans\">T-Mobile’s cheapest home internet plan</a>, for example, costs up to $55 per month for download speeds up to 415Mbps.&nbsp;</p>\n\n<p class=\"has-text-align-none\">Verizon will throttle your service by up to 10Mbps after the first 150GB of data usage in one month, while <a href=\"https://www.t-mobile.com/responsibility/consumer-info/policies/internet-service/network-management-practices#:~:text=As%20of%20May%208%2C%202024%2C%20T%2DMobile%20Internet%20customers%20using%20more%20than%201.2TB%20of%20data%20in%20a%20billing%20cycle%20are%20also%20considered%20Heavy%20Data%20Users.\">T-Mobile will start slowing down internet speeds</a> if customers use more than 1.2TB in one month. Like T-Mobile, Mint Mobile’s new prepaid home internet plan also offers download speeds of up to 415Mbps, but it will start throttling data after 1TB of usage and costs up to $50 per month.</p>\n\n<p class=\"has-text-align-none\">Verizon Lite is available across the US starting today. The carrier will likely only continue to expand its home internet coverage in the coming months, as it’s set to acquire the <a href=\"https://www.theverge.com/news/668614/verizon-frontier-acquisition-fcc-approval\">fiber internet provider Frontier</a> and the <a href=\"https://www.theverge.com/news/796693/verizon-starry-acquisition-wireless-internet-mmwave\">antenna-based internet service Starry</a>.</p>",
      "url": "https://www.theverge.com/news/806083/verizon-lite-home-internet-plan-launch-price",
      "image": "",
      "publishedAt": "2025-10-24T09:38:54-04:00",
      "lang": "en",
      "source": {
        "id": "www.theverge.com",
        "name": "The Verge",
        "url": "https://www.theverge.com/rss/index.xml",
        "country": ""
      }
    }
  },
  {
    "source": "Wired",
    "url": "https://www.wired.com/feed/rss",
    "coverage": 88.9,
    "example": {
      "id": 6832392319,
      "title": "Best 360 Cameras (2025), Tested and Reviewed",
      "description": "It’s a small world after all, and these cameras can capture all of it at once, giving you a 360-degree view.",
      "content": "It’s a small world after all, and these cameras can capture all of it at once, giving you a 360-degree view.",
      "url": "https://www.wired.com/gallery/best-360-cameras/",
      "image": "",
      "publishedAt": "Fri, 24 Oct 2025 13:00:00 +0000",
      "lang": "en",
      "source": {
        "id": "www.wired.com",
        "name": "Wired",
        "url": "https://www.wired.com/feed/rss",
        "country": ""
      }
    }
  },
  {
    "source": "Ars Technica",
    "url": "https://feeds.arstechnica.com/arstechnica/index",
    "coverage": 100.0,
    "example": {
      "id": 6397048594,
      "title": "Rocket Report: China tests Falcon 9 lookalike; NASA’s Moon rocket fully stacked",
      "description": "A South Korean rocket startup will soon make its first attempt to reach low-Earth orbit.",
      "content": "<p>Welcome to Edition 8.16 of the Rocket Report! The 10th anniversary of SpaceX’s first Falcon 9 rocket landing is coming up at the end of this year. We’re still waiting for a second company to bring back an orbital-class booster from space for a propulsive landing. Two companies, Jeff Bezos’ Blue Origin and China’s LandSpace, could join SpaceX’s exclusive club as soon as next month. (Bezos might claim <a href=\"https://x.com/JeffBezos/status/679116636310360067\">he’s already part of the club</a>, but there’s a distinction to be made.) Each company is in the final stages of launch preparations<span class=\"s1\">—Blue Origin for its second New Glenn rocket, and LandSpace for the debut flight of its Zhuque-3 rocket. Blue Origin and LandSpace will both attempt to land their first stage boosters downrange from their launch sites. They’re not exactly in a race with one another, but it will be fascinating to see how New Glenn and Zhuque-3 perform during the uphill and downhill phases of flight, and whether one or both of the new rockets stick the landing.</span></p>\n<p>As always, we <a href=\"https://arstechnica.wufoo.com/forms/launch-stories/\">welcome reader submissions</a>. If you don’t want to miss an issue, please subscribe using the box below (the form will not appear on AMP-enabled versions of the site). Each report will include information on small-, medium-, and heavy-lift rockets, as well as a quick look ahead at the next three launches on the calendar.</p>\n<figure class=\"ars-img-shortcode id-1314289 align-center\">\n    <div>\n                        <img alt=\"\" class=\"center full\" height=\"81\" src=\"https://cdn.arstechnica.net/wp-content/uploads/2018/05/smalll.png\" width=\"560\" />\n                  </div>\n      </figure>\n\n<p><b>The race for space-based interceptors. </b>The Trump administration’s announcement of the Golden Dome missile defense shield has set off a race among US companies to develop and test space weapons, some of them on their own dime, <a href=\"https://arstechnica.com/space/2025/10/california-startup-to-demonstrate-space-weapon-on-its-own-dime/\">Ars reports</a>. One of these companies is a 3-year-old startup named Apex, which announced plans to test a space-based interceptor as soon as next year. Apex’s concept will utilize one of the company’s low-cost satellite platforms outfitted with an “Orbital Magazine” containing multiple interceptors, which will be supplied by an undisclosed third-party partner. The demonstration in low-Earth orbit could launch as soon as June 2026 and will test-fire two interceptors from Apex’s Project Shadow spacecraft. The prototype interceptors could pave the way for operational space-based interceptors to shoot down ballistic missiles. (submitted by biokleen)</p><p><a href=\"https://arstechnica.com/space/2025/10/rocket-report-china-tests-falcon-9-lookalike-nasas-moon-rocket-fully-stacked/\">Read full article</a></p>\n<p><a href=\"https://arstechnica.com/space/2025/10/rocket-report-china-tests-falcon-9-lookalike-nasas-moon-rocket-fully-stacked/#comments\">Comments</a></p>",
      "url": "https://arstechnica.com/space/2025/10/rocket-report-china-tests-falcon-9-lookalike-nasas-moon-rocket-fully-stacked/",
      "image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/artemisiistacked-1152x648-1761259328.jpg",
      "publishedAt": "Fri, 24 Oct 2025 11:00:36 +0000",
      "lang": "en",
      "source": {
        "id": "feeds.arstechnica.com",
        "name": "Ars Technica",
        "url": "https://feeds.arstechnica.com/arstechnica/index",
        "country": ""
      }
    }
  },
  {
    "source": "Engadget",
    "url": "https://www.engadget.com/rss.xml",
    "coverage": 88.9,
    "example": {
      "id": 5983833419,
      "title": "Dodgers vs. Blue Jays, Game 1: How to watch the 2025 MLB World Series without cable",
      "description": "<p>The League Championship Series are history, and the final two teams have emerged: The 2025 Fall Classic will see the <a href=\"https://sports.yahoo.com/mlb/article/world-series-2025-dodgers-vs-blue-jays-position-matchups-how-they-win-how-they-lose-series-predictions-and-more-230536750.html\">Los Angeles Dodgers face the Toronto Blue Jays</a>. Game 1 of the 2025 MLB World Series begins tonight — Friday, Oct. 24 — at 8PM ET/5PM PT, with the Blue Jays getting the initial home field advantage at <a class=\"rapid-with-clickid\" href=\"https://shopping.yahoo.com/rdlw?merchantId=3daa87f2-c6d3-40c7-9637-c8aa7895a6c1&amp;siteId=us-engadget&amp;pageId=1p-autolink&amp;contentUuid=53b0e584-863f-4f2c-b173-4b978fcf200e&amp;featureId=text-link&amp;merchantName=StubHub&amp;linkText=Rogers+Centre%2C+Toronto&amp;custData=eyJzb3VyY2VOYW1lIjoiV2ViLURlc2t0b3AtVmVyaXpvbiIsImxhbmRpbmdVcmwiOiJodHRwczovL3d3dy5zdHViaHViLmNvbS90b3JvbnRvLWJsdWUtamF5cy10b3JvbnRvLXRpY2tldHMtMTAtMjQtMjAyNS9ldmVudC8xNTg5ODY5NDQvP2JhY2tVcmw9JTJGd29ybGQtc2VyaWVzLXRpY2tldHMlMkZncm91cGluZyUyRjEyMTQxOCIsImNvbnRlbnRVdWlkIjoiNTNiMGU1ODQtODYzZi00ZjJjLWIxNzMtNGI5NzhmY2YyMDBlIiwib3JpZ2luYWxVcmwiOiJodHRwczovL3d3dy5zdHViaHViLmNvbS90b3JvbnRvLWJsdWUtamF5cy10b3JvbnRvLXRpY2tldHMtMTAtMjQtMjAyNS9ldmVudC8xNTg5ODY5NDQvP2JhY2tVcmw9JTJGd29ybGQtc2VyaWVzLXRpY2tldHMlMkZncm91cGluZyUyRjEyMTQxOCJ9&amp;signature=AQAAAYoJm3LrQzli7Xz2F2W8otSxGyE04YspvOzM8WmOxK_O&amp;gcReferrer=https%3A%2F%2Fwww.stubhub.com%2Ftoronto-blue-jays-toronto-tickets-10-24-2025%2Fevent%2F158986944%2F%3FbackUrl%3D%252Fworld-series-tickets%252Fgrouping%252F121418\">Rogers Centre, Toronto</a>. Shohei Ohtani and the Dodgers are aiming to win their second consecutive championship, while Vlad Guerrero Jr. and the Blue Jays are eyeing their first ring since 1993. The World Series <a href=\"https://sports.yahoo.com/mlb/los-angeles-dodgers-toronto-blue-jays-451024114/\">odds favor the Dodgers </a>ahead of Game 1. Every 2025 MLB World Series game will air on Fox and Fox Deportes.&nbsp;</p> \n<p>Of course, Fox is a \"free\" over-the-air channel, so any affordable <a class=\"rapid-with-clickid\" href=\"https://shopping.yahoo.com/rdlw?merchantId=63045c63-8df1-46e8-bdd0-1716edf6ace5&amp;itemId=amazon_B074TWSQFM&amp;siteId=us-engadget&amp;pageId=1p-autolink&amp;contentUuid=53b0e584-863f-4f2c-b173-4b978fcf200e&amp;featureId=text-link&amp;merchantName=Amazon+Canada&amp;linkText=digital+antenna&amp;custData=eyJzb3VyY2VOYW1lIjoiV2ViLURlc2t0b3AtVmVyaXpvbiIsImxhbmRpbmdVcmwiOiJodHRwczovL3d3dy5hbWF6b24uY29tL0NoYW5uZWwtTWFzdGVyLUZMQVRlbm5hLVVsdHJhLVRoaW4tQW50ZW5uYS9kcC9CMDc0VFdTUUZNLz90YWc9Z2RndDBjLTIwIiwiY29udGVudFV1aWQiOiI1M2IwZTU4NC04NjNmLTRmMmMtYjE3My00Yjk3OGZjZjIwMGUiLCJvcmlnaW5hbFVybCI6Imh0dHBzOi8vd3d3LmFtYXpvbi5jb20vQ2hhbm5lbC1NYXN0ZXItRkxBVGVubmEtVWx0cmEtVGhpbi1BbnRlbm5hL2RwL0IwNzRUV1NRRk0vIiwiZHluYW1pY0NlbnRyYWxUcmFja2luZ0lkIjp0cnVlLCJzaXRlSWQiOiJ1cy1lbmdhZGdldCIsInBhZ2VJZCI6IjFwLWF1dG9saW5rIiwiZmVhdHVyZUlkIjoidGV4dC1saW5rIn0&amp;signature=AQAAAbEe-T3Br4v8xKPF2kjeM4bYvtmbWkJUvaiHsQPA5xL4&amp;gcReferrer=https%3A%2F%2Fwww.amazon.com%2FChannel-Master-FLATenna-Ultra-Thin-Antenna%2Fdp%2FB074TWSQFM%2F\">digital antenna</a> will pull in the game if you live close enough to a local affiliate. But if that's not an option, here's a full rundown of how to watch the Dodgers vs. Blue Jays World Series, even without cable.</p> <span id=\"end-legacy-contents\"></span> \n<h2 id=\"jump-link-how-to-watch-the-la-dodgers-vs-toronto-blue-jays-game-1\">How to watch the L.A. Dodgers vs. Toronto Blue Jays, Game 1</h2> \n<p>You can stream Fox on any <a href=\"https://www.engadget.com/entertainment/streaming/best-live-tv-streaming-service-133000410.html\">live TV streaming service</a> that airs Fox local stations, including DirecTV, Fubo and Hulu + Live TV. MLB World Series games will also be available on Fox's new streaming platform, <a href=\"https://www.engadget.com/entertainment/streaming/fox-one-streaming-service-launches-august-21-164512558.html\">Fox One</a>.</p> \n<p></p> \n<p> </p> \n<p> </p> \n<p> </p> \n<p> </p> \n<h2 id=\"jump-link-los-angeles-dodgers-vs-toronto-blue-jays-world-series-schedule\"></h2> \n<h2 id=\"jump-link-more-ways-to-watch-the-2025-world-series\">More ways to watch the 2025 World Series</h2> \n<p> </p> \n<p> </p> \n<p> </p> \n<h2 id=\"jump-link-when-is-the-dodgers-vs-blue-jays-game-time\">When is the Dodgers vs. Blue Jays game time?</h2> \n<p>Game 1 of the Dodgers vs. Blue Jays World Series begins on Friday, Oct. 24 at 8PM ET/5PM PT. The Blue Jays are hosting the first two games of the series at <a class=\"rapid-with-clickid\" href=\"https://shopping.yahoo.com/rdlw?merchantId=3daa87f2-c6d3-40c7-9637-c8aa7895a6c1&amp;siteId=us-engadget&amp;pageId=1p-autolink&amp;contentUuid=53b0e584-863f-4f2c-b173-4b978fcf200e&amp;featureId=text-link&amp;merchantName=StubHub&amp;linkText=Rogers+Centre%2C+Toronto&amp;custData=eyJzb3VyY2VOYW1lIjoiV2ViLURlc2t0b3AtVmVyaXpvbiIsImxhbmRpbmdVcmwiOiJodHRwczovL3d3dy5zdHViaHViLmNvbS90b3JvbnRvLWJsdWUtamF5cy10b3JvbnRvLXRpY2tldHMtMTAtMjQtMjAyNS9ldmVudC8xNTg5ODY5NDQvP2JhY2tVcmw9JTJGd29ybGQtc2VyaWVzLXRpY2tldHMlMkZncm91cGluZyUyRjEyMTQxOCIsImNvbnRlbnRVdWlkIjoiNTNiMGU1ODQtODYzZi00ZjJjLWIxNzMtNGI5NzhmY2YyMDBlIiwib3JpZ2luYWxVcmwiOiJodHRwczovL3d3dy5zdHViaHViLmNvbS90b3JvbnRvLWJsdWUtamF5cy10b3JvbnRvLXRpY2tldHMtMTAtMjQtMjAyNS9ldmVudC8xNTg5ODY5NDQvP2JhY2tVcmw9JTJGd29ybGQtc2VyaWVzLXRpY2tldHMlMkZncm91cGluZyUyRjEyMTQxOCJ9&amp;signature=AQAAAYoJm3LrQzli7Xz2F2W8otSxGyE04YspvOzM8WmOxK_O&amp;gcReferrer=https%3A%2F%2Fwww.stubhub.com%2Ftoronto-blue-jays-toronto-tickets-10-24-2025%2Fevent%2F158986944%2F%3FbackUrl%3D%252Fworld-series-tickets%252Fgrouping%252F121418\">Rogers Centre, Toronto</a>.</p> \n<h2 id=\"jump-link-what-channel-is-playing-the-los-angeles-dodgers-vs-toronto-blue-jays\">What channel is playing the Los Angeles Dodgers vs. Toronto Blue Jays?</h2> \n<p>Every game in the 2025 World Series between the Los Angeles Dodgers and the Toronto Blue Jays, will air on Fox and Fox Deportes.</p> \n<h2 id=\"jump-link-when-is-the-2025-world-series\">When is the 2025 World Series?</h2> \n<p>Game 1 of the World Series between the Dodgers and Blue Jays is scheduled for Friday, Oct. 24.</p> \n<h2 id=\"jump-link-los-angeles-dodgers-vs-toronto-blue-jays-world-series-schedule\"><strong>Los Angeles Dodgers vs. Toronto Blue Jays World Series schedule</strong></h2> \n<p><em>All times Eastern</em></p> \n<ul> \n <li><p><strong>Game 1:</strong> Friday, Oct. 24, 8PM ET</p></li> \n <li><p><strong>Game 2:</strong> Saturday, Oct. 25, 8PM ET</p></li> \n <li><p><strong>Game 3:</strong> Monday, Oct. 27, 8PM ET</p></li> \n <li><p><strong>Game 4: </strong>Tuesday, Oct. 28, 8PM ET</p></li> \n <li><p><strong>Game 5*:</strong> Wednesday, Oct. 29, 8PM ET</p></li> \n <li><p><strong>Game 6*:</strong> Friday, Oct. 31, 8PM ET</p></li> \n <li><p><strong>Game 7*:</strong> Saturday, Nov. 1, 8PM ET</p></li> \n</ul> \n<p><em>*if necessary</em></p> \n<p></p> \n<h2 id=\"jump-link-\"></h2> \n<h2 id=\"jump-link-\"></h2> \n<h2 id=\"jump-link-\"></h2> \n<p></p> \n<p></p> \n<p></p>This article originally appeared on Engadget at https://www.engadget.com/entertainment/streaming/dodgers-vs-blue-jays-game-1-how-to-watch-the-2025-mlb-world-series-without-cable-133403870.html?src=rss",
      "content": "",
      "url": "https://www.engadget.com/entertainment/streaming/dodgers-vs-blue-jays-game-1-how-to-watch-the-2025-mlb-world-series-without-cable-133403870.html?src=rss",
      "image": "https://o.aolcdn.com/images/dims?image_uri=https%3A%2F%2Fs.yimg.com%2Fos%2Fcreatr-uploaded-images%2F2025-10%2F2d48fa60-abf5-11f0-a7bf-558ce1159675&resize=1400%2C1009&client=19f2b5e49a271b2bde77&signature=0821994bf810aeb9dee791df52e4a79e51e1ef0c",
      "publishedAt": "Fri, 24 Oct 2025 13:34:03 +0000",
      "lang": "en",
      "source": {
        "id": "www.engadget.com",
        "name": "Engadget",
        "url": "https://www.engadget.com/rss.xml",
        "country": ""
      }
    }
  },
  {
    "source": "ZDNet",
    "url": "https://www.zdnet.com/news/rss.xml",
    "coverage": 88.9,
    "example": {
      "id": 877583995,
      "title": "Not enough people are talking about this Windows laptop that checks all the boxes for me",
      "description": "With its vibrant OLED display and all-day battery life, Acer's Swift 16 AI strikes the perfect balance between premium features and an affordable price.",
      "content": "With its vibrant OLED display and all-day battery life, Acer's Swift 16 AI strikes the perfect balance between premium features and an affordable price.",
      "url": "https://www.zdnet.com/article/not-enough-people-are-talking-about-this-windows-laptop-that-checks-all-the-boxes-for-me/",
      "image": "",
      "publishedAt": "Fri, 24 Oct 2025 13:31:00 GMT",
      "lang": "en",
      "source": {
        "id": "www.zdnet.com",
        "name": "ZDNet",
        "url": "https://www.zdnet.com/news/rss.xml",
        "country": ""
      }
    }
  },
  {
    "source": "CNET",
    "url": "https://www.cnet.com/rss/news/",
    "coverage": 100.0,
    "example": {
      "id": 9268964502,
      "title": "Disney Plus: 27 Best TV Shows to Stream Right Now",
      "description": "Disney's streamer has the must-see shows from Marvel, Star Wars and more.",
      "content": "Disney's streamer has the must-see shows from Marvel, Star Wars and more.",
      "url": "https://www.cnet.com/tech/services-and-software/best-disney-plus-tv-shows-2025/#ftag=CAD590a51e",
      "image": "https://www.cnet.com/a/img/resize/e3008458c347094f36d2025723b79666248fed2f/hub/2024/09/27/82bffd9f-b101-43d0-8f15-f3d57be17e09/agatha-all-along-cast-key-art-marvel-disney-plus.jpg?auto=webp&fit=crop&height=614&width=1092",
      "publishedAt": "Fri, 24 Oct 2025 12:45:03 +0000",
      "lang": "en",
      "source": {
        "id": "www.cnet.com",
        "name": "CNET",
        "url": "https://www.cnet.com/rss/news/",
        "country": ""
      }
    }
  },
  {
    "source": "VentureBeat",
    "url": "https://venturebeat.com/feed/",
    "coverage": 88.9,
    "example": {
      "id": 54984242,
      "title": "OpenAI launches company knowledge in ChatGPT, letting you access your firm's data from Google Drive, Slack, GitHub",
      "description": "<p>Is the Google Search for internal enterprise knowledge finally here...but from <i>OpenAI</i>? It certainly seems that way. </p><p>Today, OpenAI has <a href=\"https://openai.com/index/introducing-company-knowledge/\">launched company knowledge in ChatGPT</a>, a major new capability for subscribers to ChatGPT&#x27;s paid Business, Enterprise, and Edu plans that lets them call up their company&#x27;s data directly from third-party workplace apps including Slack, SharePoint, Google Drive, Gmail, GitHub, HubSpot and combine it in ChatGPT outputs to them. </p><p>As OpenAI&#x27;s CEO of Applications Fidji Simo put it in a post on the social network X: &quot;it brings all the context from your apps (Slack, Google Drive, GitHub, etc) together in ChatGPT so you can get answers that are specific to your business.&quot;</p><div></div><p>Intriguingly, OpenAI&#x27;s blog post on the feature states that is &quot;powered by a version of GPT‑5 that’s trained to look across multiple sources to give more comprehensive and accurate answers,&quot; which sounds to me like a new fine-tuned version of the <a href=\"https://venturebeat.com/ai/openai-launches-gpt-5-not-agi-but-capable-of-generating-software-on-demand\">model family the company released back in August</a>, though there are no additional details on how it was trained. </p><p>Nonetheless, company knowledge in ChatGPT is rolling out globally and is designed to make ChatGPT a central point of access for verified organizational information, supported by secure integrations and enterprise-grade compliance controls, and give employees way faster access to their company&#x27;s information while working.</p><p>Now, instead of toggling over to Slack to find the assignment you were given and instructions, or tabbing over to Google Drive and opening up specific files to find the names and numbers you need to call, ChatGPT can deliver all that type of information directly into your chat session — if your company enables the proper connections.</p><p>As OpenAI Chief Operating Officer Brad Lightcap <a href=\"https://x.com/bradlightcap/status/1981454865454027007\">wrote in a post on the social network X</a>: &quot;company knowledge has changed how i use chatgpt at work more than anything we have built so far - let us know what you think!&quot;</p><div></div><p>It builds upon the third-party app connectors <a href=\"https://venturebeat.com/ai/openai-adds-new-chatgpt-third-party-tool-connectors-to-dropbox-ms-teams-as-altman-clarifies-gpt-5-prioritization\">unveiled back in August 2025</a>, though those were only for individual users on the ChatGPT Plus plans.</p><h3><b>Connecting ChatGPT to Workplace Systems</b></h3><p>Enterprise teams often face the challenge of fragmented data across various internal tools—email, chat, file storage, project management, and customer platforms. </p><p>Company knowledge bridges those silos by enabling ChatGPT to connect to approved systems like, and other supported apps through enterprise-managed connectors.</p><p>Each response generated with company knowledge includes citations and direct links to the original sources, allowing teams to verify where specific details originated. This transparency helps organizations maintain data trustworthiness while increasing productivity.</p><p>OpenAI confirms that company knowledge uses a version of GPT-5 optimized for multi-source reasoning and cross-system synthesis, providing detailed, contextually accurate results even across disparate sources.</p><h3><b>Built for Enterprise Control and Security</b></h3><p>Company knowledge was designed from the ground up for enterprise governance and compliance. It respects existing permissions within connected apps — ChatGPT can only access what a user is already authorized to view— and never trains on company data by default.</p><p>Security features include industry-standard encryption, support for SSO and SCIM for account provisioning, and IP allowlisting to restrict access to approved corporate networks. </p><p>Enterprise administrators can also define role-based access control (RBAC) policies and manage permissions at a group or department level.</p><p>OpenAI’s Enterprise Compliance API provides a full audit trail, allowing administrators to review conversation logs for reporting and regulatory purposes. </p><p>This capability helps enterprises meet internal governance standards and industry-specific requirements such as SOC 2 and ISO 27001 compliance.</p><h3><b>Admin Configuration and Connector Management</b></h3><p>For enterprise deployment, administrators must enable company knowledge and its connectors within the ChatGPT workspace. Once connectors are active, users can authenticate their own accounts for each work app they need to access.</p><p>In Enterprise and Edu plans, connectors are off by default and require explicit admin approval before employees can use them. Admins can selectively enable connectors, manage access by role, and require SSO-based authentication for enhanced control.</p><p>Business plan users, by contrast, have connectors enabled automatically if available in their workspace. Admins can still oversee which connectors are approved, ensuring alignment with internal IT and data policies.</p><p>Company knowledge becomes available to any user with at least one active connector, and admins can configure group-level permissions for different teams — such as restricting GitHub access to engineering while enabling Google Drive or HubSpot for marketing and sales.</p><h3><b>How Company Knowledge Works in Practice</b></h3><p>Activating company knowledge is straightforward. Users can start a new or existing conversation in ChatGPT and select “Company knowledge” under the message composer or from the tools menu. </p><p>After authenticating their connected apps, they can ask questions as usual—such as “Summarize this account’s latest feedback and risks” or “Compile a Q4 performance summary from project trackers.”</p><p>ChatGPT searches across the connected tools, retrieves relevant context, and produces an answer with full citations and source links. </p><p>The system can combine data across apps — for instance, blending Slack updates, Google Docs notes, and HubSpot CRM records — to create an integrated view of a project, client, or initiative.</p><p>When company knowledge is not selected, ChatGPT may still use connectors in a limited capacity as part of the default experience, but responses will not include detailed citations or multi-source synthesis.</p><h3><b>Advanced Use Cases for Enterprise Teams</b></h3><p>For development and operations leaders, company knowledge can act as a centralized intelligence layer that surfaces real-time updates and dependencies across complex workflows. ChatGPT can, for example, summarize open GitHub pull requests, highlight unresolved Linear tickets, and cross-reference Slack engineering discussions—all in a single output.</p><p>Technical teams can also use it for incident retrospectives or release planning by pulling relevant information from issue trackers, logs, and meeting notes. Procurement or finance leaders can use it to consolidate purchase requests or budget updates across shared drives and internal communications.</p><p>Because the model can reference structured and unstructured data simultaneously, it supports wide-ranging scenarios—from compliance documentation reviews to cross-departmental performance summaries.</p><h3><b>Privacy, Data Residency, and Compliance</b></h3><p>Enterprise data protection is a central design element of company knowledge. ChatGPT processes data in line with OpenAI’s enterprise-grade security model, ensuring that no connected app data leaves the secure boundary of the organization’s authorized environment.</p><p>Data residency policies vary by connector. Certain integrations, such as Slack, support region-specific data storage, while others—like Google Drive and SharePoint—are available for U.S.-based customers with or without at-rest data residency. Organizations with regional compliance obligations can review connector-specific security documentation for details.</p><p>No geo restrictions apply to company knowledge, making it suitable for multinational organizations operating across multiple jurisdictions.</p><h3><b>Limitations and Future Enhancements</b></h3><p>At present, users must manually enable company knowledge in each new ChatGPT conversation. </p><p>OpenAI is developing a unified interface that will automatically integrate company knowledge with other ChatGPT tools—such as browsing and chart generation—so that users won’t need to toggle between modes.</p><p>When enabled, company knowledge temporarily disables web browsing and visual output generation, though users can switch modes within the same conversation to re-enable those features.</p><p>OpenAI also continues to expand the network of supported tools. Recent updates have added connectors for Asana, GitLab Issues, and ClickUp, and OpenAI plans to support future MCP (Model Context Protocol) connectors to enable custom, developer-built integrations.</p><p>Several important details about <i>company knowledge</i> remain unclear based on OpenAI’s published materials. It’s not yet known whether the system can detect and exclude information labeled as confidential, whether organizations can opt in or out of data training separately for this feature, or if users will eventually be able to select which model powers it. </p><p>OpenAI has also not said whether this version of GPT-5 is new or specific to the feature, or what service-level guarantees exist to ensure accuracy and prevent hallucinations in company-specific responses. VentureBeat has emailed OpenAI spokespeople with these and related questions and is awaiting a response, which we will publish if and when we receive it.</p><h3><b>Availability and Getting Started</b></h3><p>Company knowledge is now available to all ChatGPT Business, Enterprise, and Edu users. Organizations can begin by enabling the feature under the ChatGPT message composer and connecting approved work apps.</p><p>For enterprise rollouts, OpenAI recommends a phased deployment: first enabling core connectors (such as Google Drive and Slack), configuring RBAC and SSO, then expanding to specialized systems once data access policies are verified.</p><p>Procurement and security leaders evaluating the feature should note that company knowledge is covered under existing ChatGPT Enterprise terms and uses the same encryption, compliance, and service-level guarantees.</p><p>With company knowledge, OpenAI aims to make ChatGPT not just a conversational assistant but an intelligent interface to enterprise data—delivering secure, context-aware insights that help technical and business leaders act with confidence.</p>",
      "content": "<p>Is the Google Search for internal enterprise knowledge finally here...but from <i>OpenAI</i>? It certainly seems that way. </p><p>Today, OpenAI has <a href=\"https://openai.com/index/introducing-company-knowledge/\">launched company knowledge in ChatGPT</a>, a major new capability for subscribers to ChatGPT&#x27;s paid Business, Enterprise, and Edu plans that lets them call up their company&#x27;s data directly from third-party workplace apps including Slack, SharePoint, Google Drive, Gmail, GitHub, HubSpot and combine it in ChatGPT outputs to them. </p><p>As OpenAI&#x27;s CEO of Applications Fidji Simo put it in a post on the social network X: &quot;it brings all the context from your apps (Slack, Google Drive, GitHub, etc) together in ChatGPT so you can get answers that are specific to your business.&quot;</p><div></div><p>Intriguingly, OpenAI&#x27;s blog post on the feature states that is &quot;powered by a version of GPT‑5 that’s trained to look across multiple sources to give more comprehensive and accurate answers,&quot; which sounds to me like a new fine-tuned version of the <a href=\"https://venturebeat.com/ai/openai-launches-gpt-5-not-agi-but-capable-of-generating-software-on-demand\">model family the company released back in August</a>, though there are no additional details on how it was trained. </p><p>Nonetheless, company knowledge in ChatGPT is rolling out globally and is designed to make ChatGPT a central point of access for verified organizational information, supported by secure integrations and enterprise-grade compliance controls, and give employees way faster access to their company&#x27;s information while working.</p><p>Now, instead of toggling over to Slack to find the assignment you were given and instructions, or tabbing over to Google Drive and opening up specific files to find the names and numbers you need to call, ChatGPT can deliver all that type of information directly into your chat session — if your company enables the proper connections.</p><p>As OpenAI Chief Operating Officer Brad Lightcap <a href=\"https://x.com/bradlightcap/status/1981454865454027007\">wrote in a post on the social network X</a>: &quot;company knowledge has changed how i use chatgpt at work more than anything we have built so far - let us know what you think!&quot;</p><div></div><p>It builds upon the third-party app connectors <a href=\"https://venturebeat.com/ai/openai-adds-new-chatgpt-third-party-tool-connectors-to-dropbox-ms-teams-as-altman-clarifies-gpt-5-prioritization\">unveiled back in August 2025</a>, though those were only for individual users on the ChatGPT Plus plans.</p><h3><b>Connecting ChatGPT to Workplace Systems</b></h3><p>Enterprise teams often face the challenge of fragmented data across various internal tools—email, chat, file storage, project management, and customer platforms. </p><p>Company knowledge bridges those silos by enabling ChatGPT to connect to approved systems like, and other supported apps through enterprise-managed connectors.</p><p>Each response generated with company knowledge includes citations and direct links to the original sources, allowing teams to verify where specific details originated. This transparency helps organizations maintain data trustworthiness while increasing productivity.</p><p>OpenAI confirms that company knowledge uses a version of GPT-5 optimized for multi-source reasoning and cross-system synthesis, providing detailed, contextually accurate results even across disparate sources.</p><h3><b>Built for Enterprise Control and Security</b></h3><p>Company knowledge was designed from the ground up for enterprise governance and compliance. It respects existing permissions within connected apps — ChatGPT can only access what a user is already authorized to view— and never trains on company data by default.</p><p>Security features include industry-standard encryption, support for SSO and SCIM for account provisioning, and IP allowlisting to restrict access to approved corporate networks. </p><p>Enterprise administrators can also define role-based access control (RBAC) policies and manage permissions at a group or department level.</p><p>OpenAI’s Enterprise Compliance API provides a full audit trail, allowing administrators to review conversation logs for reporting and regulatory purposes. </p><p>This capability helps enterprises meet internal governance standards and industry-specific requirements such as SOC 2 and ISO 27001 compliance.</p><h3><b>Admin Configuration and Connector Management</b></h3><p>For enterprise deployment, administrators must enable company knowledge and its connectors within the ChatGPT workspace. Once connectors are active, users can authenticate their own accounts for each work app they need to access.</p><p>In Enterprise and Edu plans, connectors are off by default and require explicit admin approval before employees can use them. Admins can selectively enable connectors, manage access by role, and require SSO-based authentication for enhanced control.</p><p>Business plan users, by contrast, have connectors enabled automatically if available in their workspace. Admins can still oversee which connectors are approved, ensuring alignment with internal IT and data policies.</p><p>Company knowledge becomes available to any user with at least one active connector, and admins can configure group-level permissions for different teams — such as restricting GitHub access to engineering while enabling Google Drive or HubSpot for marketing and sales.</p><h3><b>How Company Knowledge Works in Practice</b></h3><p>Activating company knowledge is straightforward. Users can start a new or existing conversation in ChatGPT and select “Company knowledge” under the message composer or from the tools menu. </p><p>After authenticating their connected apps, they can ask questions as usual—such as “Summarize this account’s latest feedback and risks” or “Compile a Q4 performance summary from project trackers.”</p><p>ChatGPT searches across the connected tools, retrieves relevant context, and produces an answer with full citations and source links. </p><p>The system can combine data across apps — for instance, blending Slack updates, Google Docs notes, and HubSpot CRM records — to create an integrated view of a project, client, or initiative.</p><p>When company knowledge is not selected, ChatGPT may still use connectors in a limited capacity as part of the default experience, but responses will not include detailed citations or multi-source synthesis.</p><h3><b>Advanced Use Cases for Enterprise Teams</b></h3><p>For development and operations leaders, company knowledge can act as a centralized intelligence layer that surfaces real-time updates and dependencies across complex workflows. ChatGPT can, for example, summarize open GitHub pull requests, highlight unresolved Linear tickets, and cross-reference Slack engineering discussions—all in a single output.</p><p>Technical teams can also use it for incident retrospectives or release planning by pulling relevant information from issue trackers, logs, and meeting notes. Procurement or finance leaders can use it to consolidate purchase requests or budget updates across shared drives and internal communications.</p><p>Because the model can reference structured and unstructured data simultaneously, it supports wide-ranging scenarios—from compliance documentation reviews to cross-departmental performance summaries.</p><h3><b>Privacy, Data Residency, and Compliance</b></h3><p>Enterprise data protection is a central design element of company knowledge. ChatGPT processes data in line with OpenAI’s enterprise-grade security model, ensuring that no connected app data leaves the secure boundary of the organization’s authorized environment.</p><p>Data residency policies vary by connector. Certain integrations, such as Slack, support region-specific data storage, while others—like Google Drive and SharePoint—are available for U.S.-based customers with or without at-rest data residency. Organizations with regional compliance obligations can review connector-specific security documentation for details.</p><p>No geo restrictions apply to company knowledge, making it suitable for multinational organizations operating across multiple jurisdictions.</p><h3><b>Limitations and Future Enhancements</b></h3><p>At present, users must manually enable company knowledge in each new ChatGPT conversation. </p><p>OpenAI is developing a unified interface that will automatically integrate company knowledge with other ChatGPT tools—such as browsing and chart generation—so that users won’t need to toggle between modes.</p><p>When enabled, company knowledge temporarily disables web browsing and visual output generation, though users can switch modes within the same conversation to re-enable those features.</p><p>OpenAI also continues to expand the network of supported tools. Recent updates have added connectors for Asana, GitLab Issues, and ClickUp, and OpenAI plans to support future MCP (Model Context Protocol) connectors to enable custom, developer-built integrations.</p><p>Several important details about <i>company knowledge</i> remain unclear based on OpenAI’s published materials. It’s not yet known whether the system can detect and exclude information labeled as confidential, whether organizations can opt in or out of data training separately for this feature, or if users will eventually be able to select which model powers it. </p><p>OpenAI has also not said whether this version of GPT-5 is new or specific to the feature, or what service-level guarantees exist to ensure accuracy and prevent hallucinations in company-specific responses. VentureBeat has emailed OpenAI spokespeople with these and related questions and is awaiting a response, which we will publish if and when we receive it.</p><h3><b>Availability and Getting Started</b></h3><p>Company knowledge is now available to all ChatGPT Business, Enterprise, and Edu users. Organizations can begin by enabling the feature under the ChatGPT message composer and connecting approved work apps.</p><p>For enterprise rollouts, OpenAI recommends a phased deployment: first enabling core connectors (such as Google Drive and Slack), configuring RBAC and SSO, then expanding to specialized systems once data access policies are verified.</p><p>Procurement and security leaders evaluating the feature should note that company knowledge is covered under existing ChatGPT Enterprise terms and uses the same encryption, compliance, and service-level guarantees.</p><p>With company knowledge, OpenAI aims to make ChatGPT not just a conversational assistant but an intelligent interface to enterprise data—delivering secure, context-aware insights that help technical and business leaders act with confidence.</p>",
      "url": "https://venturebeat.com/ai/openai-launches-company-knowledge-in-chatgpt-letting-you-access-your-firms",
      "image": "",
      "publishedAt": "Thu, 23 Oct 2025 22:19:00 GMT",
      "lang": "en",
      "source": {
        "id": "venturebeat.com",
        "name": "VentureBeat",
        "url": "https://venturebeat.com/feed/",
        "country": ""
      }
    }
  },
  {
    "source": "GitHub Blog",
    "url": "https://github.blog/feed/",
    "coverage": 88.9,
    "example": {
      "id": 9030077045,
      "title": "The road to better completions: Building a faster, smarter GitHub Copilot with a new custom model",
      "description": "<p>Find out about the latest custom models powering the completions experience in GitHub Copilot. </p>\n<p>The post <a href=\"https://github.blog/ai-and-ml/github-copilot/the-road-to-better-completions-building-a-faster-smarter-github-copilot-with-a-new-custom-model/\">The road to better completions: Building a faster, smarter GitHub Copilot with a new custom model</a> appeared first on <a href=\"https://github.blog\">The GitHub Blog</a>.</p>",
      "content": "<p>Code completion remains the most widely used GitHub Copilot feature, helping millions of developers stay in the flow every day. Our team has continuously iterated on the custom models powering the completions experience in GitHub Copilot driven by developer feedback. That work has had a big impact on giving you faster, more relevant suggestions in the editor.&nbsp;&nbsp;</p>\n\n\n\n<p>We&rsquo;re now delivering suggestions with 20% more accepted and retained characters, 12% higher acceptance rate, 3x higher token-per-second throughput, and a 35% reduction in latency.&nbsp;</p>\n\n\n\n<p>These updates now power GitHub Copilot across editors and environments. We&rsquo;d like to share our journey on how we trained and evaluated our custom model for code completions.&nbsp;</p>\n\n\n\n<h2 class=\"wp-block-heading\" id=\"h-why-it-matters-nbsp\">Why it matters&nbsp;</h2>\n\n\n\n<p>When Copilot completions improve, you spend less time editing and more time building. The original Copilot was optimized for the highest acceptance rate possible. However, we realized that a heavy focus on acceptance rates could lead to incorrectly favoring a high volume of simple and short suggestions.&nbsp;&nbsp;</p>\n\n\n\n<p>We heard your feedback that this didn&rsquo;t reflect real developer needs or deliver the highest quality experience. So, we pivoted to also optimize for accepted and retained characters, code flow, and other metrics.&nbsp;</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>20% higher accepted-and-retained characters</strong> results in more of each Copilot suggestion staying in your final code, not just ending up temporarily accepted and deleted later. In other words, suggestions provide more value with fewer keystrokes.</li>\n\n\n\n<li><strong>12% higher acceptance rate</strong> means you find suggestions more useful more often, reflecting better immediate utility.&nbsp;</li>\n\n\n\n<li><strong>3x throughput</strong> <strong>with 35% lower latency</strong> makes Copilot feel faster. It handles more requests at once while keeping your coding flow unbroken (throughput describes how much work the system can handle overall, while latency describes how quickly each individual request completes).</li>\n</ul>\n\n\n\n<h2 class=\"wp-block-heading\" id=\"h-how-we-evaluate-custom-models-nbsp\">How we evaluate custom models&nbsp;</h2>\n\n\n\n<p>Copilot models are evaluated using combined signals from <strong>offline</strong>, <strong>pre-production</strong>, and <strong>production</strong> evaluations. Each layer helps us refine different aspects of the experience while ensuring better quality in real developer workflows.&nbsp;</p>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-1-offline-evaluations-nbsp-nbsp\">1) Offline evaluations&nbsp;&nbsp;</h3>\n\n\n\n<p><strong>Execution-based benchmark: </strong>As part of our offline evaluations, we first test against internal and public repositories with strong code by unit test and scenario coverage, spanning all major languages. Each test simulates real tasks, accepts suggestions, and measures build-and-test pass rates. This emphasizes functional correctness over surface fluency.&nbsp;&nbsp;</p>\n\n\n\n<p>Below is an example of a partial token completion error: the model produced <code>data<strong>et</strong></code> instead of <code>data<strong>set</strong></code>.</p>\n\n\n\n<figure class=\"wp-block-image size-large\"><img alt=\"Screenshot of a Python code editor showing a function named resolve_file inside a file called dataset_utilities.py. The function takes two string arguments, dataset and filename, and returns a string. The purpose, according to the docstring, is to resolve a file from a dataset and assert that only one file is found. The code uses os.path and glob to find files. There&rsquo;s a highlighted line path = os.path.join(dat... with an error under dat, suggesting a variable name typo (dat instead of dataset). Several red underlines indicate syntax or reference errors in the code.\" class=\"wp-image-91828\" height=\"447\" src=\"https://github.blog/wp-content/uploads/2025/10/partial-token-completion-error.png?resize=1024%2C447\" width=\"1024\" /></figure>\n\n\n\n<p><strong>LLM-judge scoring: </strong>While we start with execution-based evaluation, this has downsides: it only tells if the code will compile, but the results are not always aligned with developer preferences. To ensure the best possible outcomes, we run an independent LLM to score completions across three axes:&nbsp;&nbsp;</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Quality:</strong> Ensure syntax validity, duplication/overlap, format and style consistency.&nbsp;</li>\n\n\n\n<li><strong>Relevance: </strong>Focus on relevant code, avoid hallucination and overreach.&nbsp;</li>\n\n\n\n<li><strong>Helpfulness:</strong> Reduce manual effort, avoid outdated or deprecated APIs.&nbsp;</li>\n</ul>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-2-pre-production-evaluations-qualitative-dogfooding-nbsp\">2) Pre-production evaluations: Qualitative dogfooding&nbsp;</h3>\n\n\n\n<p>Our next step includes working with internal developers and partners to test models side-by-side in real workflows (to do the latter, we exposed the preview model to developers through Copilot&rsquo;s model picker). We collect structured feedback on readability, trust, and &ldquo;taste.&rdquo; Part of this process includes working with language experts to improve overall completion quality. This is unique: while execution-based testing, LLM-based evaluations, dogfood testing, and A/B testing are common, we find language-specific evaluations lead to better outcomes along quality and style preferences.&nbsp;</p>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-3-production-based-evaluations-a-b-testing-nbsp\">3) Production-based evaluations: A/B testing&nbsp;</h3>\n\n\n\n<p>Ultimately, the lived experience of developers like you is what matters most. We measure improvements using accepted-and-retained characters, acceptance rates, completion-shown rate, time-to-first token, latency, and many other metrics. We ship only when statistically significant improvements hold up under real developer workloads.&nbsp;</p>\n\n\n\n<h2 class=\"wp-block-heading\" id=\"h-how-we-trained-our-new-copilot-completions-model-nbsp\">How we trained our new Copilot completions model&nbsp;</h2>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-mid-training-nbsp\">Mid-training&nbsp;</h3>\n\n\n\n<p>Modern codebases use modern APIs. Before fine-tuning, we build a code-specific foundational model via mid-training using a curated, de-duplicated corpus of modern, idiomatic, public, and internal code with nearly 10M repositories and 600-plus programming languages. (Mid-training refers to the stage after the base model has been pretrained on a very large, diverse corpus, but before it undergoes final fine-tuning or instruction-tuning).&nbsp;</p>\n\n\n\n<p>This is a critical step to ensure behaviors, new language syntax, and recent API versions are utilized by the model. We then use supervised fine-<s> </s>tuning and reinforcement learning while mixing objectives beyond next-token prediction&mdash;span infillings and docstring/function pairs&mdash;so the model learns structure, naming, and intent, not just next-token prediction. This helps us make the foundational model code-fluent, style-consistent, and context-aware, ready for more targeted fine-tuning via supervised fine-tuning.&nbsp;</p>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-supervised-fine-tuning-nbsp\">Supervised fine-tuning&nbsp;</h3>\n\n\n\n<p>Newer general-purpose chat models perform well in natural language to generate code, but underperform on fill-in-the-middle (FIM) code completion. In practice, chat models experience cursor-misaligned inserts, duplication of code before the cursor (prefix), and overwrites of code after the cursor (suffix).&nbsp;&nbsp;</p>\n\n\n\n<p>As we moved to fine-tuned behaviors, we trained models specialized in completions by way of synthetic fine-tuning to behave like a great FIM engine. In practice, this improves:&nbsp;</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Prefix/suffix awareness</strong>: Accurate inserts between tokens, mid-line continuations, full line completions, and multi-line block completions without trampling the suffix.&nbsp;</li>\n\n\n\n<li><strong>Formatting fidelity</strong>: Respect local style (indentation, imports, docstrings) and avoid prefix duplication.&nbsp;</li>\n</ul>\n\n\n\n<p>The result is significantly improved FIM performance. For example, here is a benchmark comparing our latest completions model to GPT-4.1-mini on <a href=\"https://github.com/openai/human-eval-infilling\" rel=\"noreferrer noopener\" target=\"_blank\">OpenAI&rsquo;s HumanEval Infilling Benchmarks</a>.&nbsp;&nbsp;</p>\n\n\n\n<figure class=\"wp-block-image size-large\"><img alt=\"A chart showing HumanEval Infilling Benchmarks for two different AI models. These include a custom model from GitHub named Copilot Completions and OpenAI's GPT-4o-mini. The evaluations show superior performance across single line, multi line, random span, and random span light tests for the Copilot Completions model. \" class=\"wp-image-91837\" height=\"538\" src=\"https://github.blog/wp-content/uploads/2025/10/HumanEvalInfilling_1200x630.png?resize=1024%2C538\" width=\"1024\" /></figure>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-reinforcement-learning-nbsp\">Reinforcement learning&nbsp;</h3>\n\n\n\n<p>Finally, we used a custom reinforcement learning algorithm, teaching the model through rewards and penalties to internalize what makes code suggestions useful in real developer scenarios along three axes:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Quality</strong>: Syntax-valid, compilable code that follows project style (indentations, imports, headers).&nbsp;&nbsp;</li>\n\n\n\n<li><strong>Relevance</strong>: On-task suggestions that respect surrounding context and the file&rsquo;s intent.&nbsp;&nbsp;</li>\n\n\n\n<li><strong>Helpfulness</strong>: Suggestions that reduce manual effort and prefer modern APIs.&nbsp;&nbsp;</li>\n</ul>\n\n\n\n<p>Together, these create completions that are correct, relevant, and genuinely useful at the cursor instead of being verbose or superficially helpful.&nbsp;</p>\n\n\n\n<h2 class=\"wp-block-heading\" id=\"h-what-we-learned-nbsp\">What we learned&nbsp;</h2>\n\n\n\n<p>After talking with programming language experts and finding success in our prompt-based<s> </s>approach, one of our most important lessons was adding related files like C++ header files to our training data. Beyond this, we also came away with three key learnings:&nbsp;</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Reward carefully: </strong>Early reinforcement learning version over-optimized for longer completions, adding too many comments in the form of &ldquo;reward hacking.&rdquo; To mitigate this problem, we introduced comment guardrails to keep completions concise and focused on moving the task forward while penalizing unnecessary commentary.&nbsp;</li>\n\n\n\n<li><strong>Metrics matter: </strong>Being hyper-focused on a metric like acceptance rate can lead to experiences that look good on paper, but do not result in happy developers. That makes it critical to evaluate performance by monitoring multiple metrics with real-world impact.</li>\n\n\n\n<li><strong>Train for real-world usage: </strong>We align our synthetic fine-tuning data with real-world usage and adapt our training accordingly. This helps us identify problematic patterns and remove them via training to improve real-world outcomes.&nbsp;&nbsp;</li>\n</ul>\n\n\n\n<h2 class=\"wp-block-heading\" id=\"h-what-s-next-nbsp\">What&rsquo;s next&nbsp;</h2>\n\n\n\n<p>We&rsquo;re continuing to push the frontier of Copilot completions by:&nbsp;</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>Expanding into domain-specific slices (e.g., game engines, financial, ERP).&nbsp;</li>\n\n\n\n<li>Refining reward functions for build/test success, semantic usefulness (edits that advance the user&rsquo;s intent without bloat), and API modernity preference for up-to-date, idiomatic libraries and patterns. This is helping us shape completion behavior with greater precision.&nbsp;</li>\n\n\n\n<li>Driving faster, cheaper, higher-quality completions across all developer environments.&nbsp;&nbsp;</li>\n</ul>\n\n\n\n<div class=\"wp-block-group post-content-cta has-global-padding is-layout-constrained wp-block-group-is-layout-constrained\">\n<p>Experience faster, smarter code completions yourself. <a href=\"https://github.com/features/copilot\" rel=\"noreferrer noopener\" target=\"_blank\">Try GitHub Copilot in VS Code &gt;</a>&nbsp;</p>\n</div>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"h-acknowledgments-nbsp\">Acknowledgments&nbsp;</h3>\n\n\n\n<p>First, a big shoutout to our developer community for continuing to give us feedback and push us to deliver the best possible experiences with GitHub Copilot. Moreover, a huge thanks to the researchers, engineers, product managers, designers across GitHub and Microsoft who curated the training data, built the training pipeline, evaluation suites, client and serving stack<s> </s>&mdash;<s> </s>and to the GitHub Copilot product and engineering teams for smooth model releases.&nbsp;</p>\n\n<p>The post <a href=\"https://github.blog/ai-and-ml/github-copilot/the-road-to-better-completions-building-a-faster-smarter-github-copilot-with-a-new-custom-model/\">The road to better completions: Building a faster, smarter GitHub Copilot with a new custom model</a> appeared first on <a href=\"https://github.blog\">The GitHub Blog</a>.</p>",
      "url": "https://github.blog/ai-and-ml/github-copilot/the-road-to-better-completions-building-a-faster-smarter-github-copilot-with-a-new-custom-model/",
      "image": "",
      "publishedAt": "Thu, 23 Oct 2025 18:31:12 +0000",
      "lang": "en",
      "source": {
        "id": "github.blog",
        "name": "GitHub Blog",
        "url": "https://github.blog/feed/",
        "country": ""
      }
    }
  },
  {
    "source": "Stack Overflow Blog",
    "url": "https://stackoverflow.blog/feed/",
    "coverage": 88.9,
    "example": {
      "id": 4924334840,
      "title": "Your runbooks are obsolete in the age of agents",
      "description": "Ryan is joined by Spiros Xanthos, CEO and founder of Resolve AI, to talk about the future of AI agents in incident management and troubleshooting, the challenges of maintaining complex software systems with traditional runbooks, and the changing role of developers in an AI-driven world.",
      "content": "Ryan is joined by Spiros Xanthos, CEO and founder of Resolve AI, to talk about the future of AI agents in incident management and troubleshooting, the challenges of maintaining complex software systems with traditional runbooks, and the changing role of developers in an AI-driven world.",
      "url": "https://stackoverflow.blog/2025/10/24/your-runbooks-are-obsolete-in-the-age-of-agents/",
      "image": "",
      "publishedAt": "Fri, 24 Oct 2025 07:40:00 GMT",
      "lang": "en",
      "source": {
        "id": "stackoverflow.blog",
        "name": "Stack Overflow Blog",
        "url": "https://stackoverflow.blog/feed/",
        "country": ""
      }
    }
  },
  {
    "source": "Dev.to",
    "url": "https://dev.to/feed",
    "coverage": 88.9,
    "example": {
      "id": 1341302870,
      "title": "DynamoDB Outage: Why Multi-Cloud Fails Startups (And Real DR Wins)",
      "description": "<p>If you felt like half the internet was broken this week, you weren't wrong. 📉 A massive, 15-hour outage in Amazon's <code>us-east-1</code> region took down DynamoDB and with it, a huge chunk of the web.</p>\n\n<p>This wasn't just \"a server went down.\" It was a complex, cascading failure that exposed the deep interconnectedness of cloud services. For startups and scaleups, the immediate reaction is often, \"We need to be multi-cloud to prevent this!\"</p>\n\n<p>Hold on!</p>\n\n<p>The real lesson here isn't about running from your cloud provider. It's about understanding <em>what</em> failed, why <code>us-east-1</code> is a special kind of dangerous and how to build a <em>realistic</em> Disaster Recovery (DR) plan that won't bankrupt you.</p>\n\n\n\n\n<h2>\n  \n  \n  The Anatomy of a Cascading Failure\n</h2>\n\n<p>This outage was a masterclass in how modern, automated systems can fail in spectacular ways. It wasn't one thing; it was a chain of dominoes.</p>\n\n<ol>\n<li>\n<p><strong>The Trigger: A DNS Race Condition</strong><br />\nIt all started with the system that manages the DNS for DynamoDB. Think of DNS as the Internet's phonebook. This automated system had a <strong>latent race condition</strong>—a hidden bug. Two of its own processes tried to update the DynamoDB DNS record at the <em>exact same time</em>.</p>\n\n<ul>\n<li>One process (let's call it \"Slow-Worker\") grabbed an <em>old</em> plan.</li>\n<li>A second process (\"Fast-Worker\") grabbed a <em>new</em> plan and applied it successfully.</li>\n<li>\"Fast-Worker\" then did its cleanup, deleting the <em>old</em> plan that \"Slow-Worker\" was <em>still holding</em>.</li>\n<li>\"Slow-Worker\" finally woke up and applied its plan... which was now empty.</li>\n<li>\n<strong>Result:</strong> The main DNS record for <code>dynamodb.us-east-1.amazonaws.com</code> was wiped clean. All its IP addresses vanished.</li>\n</ul>\n</li>\n<li><p><strong>The First Domino: DynamoDB Goes Offline</strong><br />\nInstantly, any application (including AWS's own internal services) attempting to access DynamoDB in that region received a \"does not exist\" error. The service was unreachable.</p></li>\n<li>\n<p><strong>The Cascade: EC2, Lambda and IAM Fall Next</strong><br />\nThis is where it gets scary. Cloud services are built on top of <em>other</em> cloud services. And DynamoDB is a <strong>Tier 0 service</strong>—a foundational block.</p>\n\n<ul>\n<li>\n<strong>EC2</strong> failed because its control plane (the \"brain\" that launches new servers) uses DynamoDB to track the state and leases of its physical hardware. No DynamoDB, no new EC2 instances.</li>\n<li>\n<strong>Lambda, ECS, EKS and Fargate</strong> all failed because they all <em>run on</em> EC2. They couldn't get new computing capacity.</li>\n<li>\n<strong>Network Load Balancers</strong> started failing health checks, causing connection errors for services that were <em>technically</em> still running.</li>\n<li>\n<strong>IAM</strong>, which handles authentication, was also impacted. This is critical: during the outage, some engineers were unable to log in to the console to fix the problem.</li>\n</ul>\n</li>\n<li>\n<p><strong>The 15-Hour Recovery and \"Congestive Collapse\"</strong><br />\nEngineers fixed the DNS record relatively quickly, but the outage lasted 15 hours. Why?</p>\n\n<ul>\n<li>\n<strong>DNS Caching:</strong> The \"empty\" (and wrong) DNS record was cached by resolvers all over the internet. They had to wait for that cache to expire.</li>\n<li>\n<strong>Congestive Collapse:</strong> When the service finally came back, a \"thundering herd\" of <em>every single service</em> retrying at once hammered DynamoDB. The system, in its weakened recovery state, was so overwhelmed by recovery work that it couldn't make forward progress. Engineers had to manually throttle traffic and drain backlogs to bring it back online safely.</li>\n</ul>\n</li>\n</ol>\n\n\n\n\n<h2>\n  \n  \n  The Global Blast Radius: Why You Should <em>Never</em> Host in <code>us-east-1</code>\n</h2>\n\n<p>\"But I don't even use <code>us-east-1</code>!\" you might say. \"I'm in <code>eu-west-3</code> (Paris)!\"</p>\n\n<p>It didn't matter. This outage had a global impact and it exposes the dirty secret of AWS: <strong><code>us-east-1</code> (N. Virginia) is not just another region.</strong></p>\n\n<p>Because it's the <em>oldest</em> AWS region, many \"global\" services have their control planes homed there by default.</p>\n\n<ul>\n<li>\n<strong>Global IAM Console:</strong> The main IAM dashboard and API are, by default, in <code>us-east-1</code>. During the outage, users in other regions reported being unable to manage permissions or roles.</li>\n<li>\n<strong>S3 Management Console:</strong> The \"global\" S3 console is also hosted there. You could still <em>access</em> your data in a bucket in Frankfurt, but you couldn't <em>manage</em> the bucket (e.g., change policies, create new buckets).</li>\n<li>\n<strong>Global Services:</strong> Services like DynamoDB Global Tables, which replicate data worldwide, saw massive replication lag to and from the failed region.</li>\n</ul>\n\n\n\n\n<h2>\n  \n  \n  The Multi-Cloud Fallacy: Doubling Your Problems, Not Your Uptime\n</h2>\n\n<p>When an event like this happens, the C-suite's first question is, \"Why aren't we on GCP and Azure, too?\"</p>\n\n<p>For a startup or scaleup, \"multi-cloud\" is a trap. It's a strategy for massive, risk-averse banks and Fortune 100s with regulatory requirements, not for a company that needs to move fast.</p>\n\n<p>Chasing multi-cloud to solve for availability is a terrible trade-off. Here’s why:</p>\n\n<ol>\n<li> <strong>Exponential Complexity:</strong> You think AWS IAM is hard? Now try to manage AWS IAM, Google Cloud IAM and Azure Entra ID and make them all talk to each other securely. Your 3-person DevOps team is now responsible for three entirely different networking stacks, security models and deployment pipelines.</li>\n<li> <strong>The \"Lowest Common Denominator\" Problem:</strong> This is the <em>killer</em>. The real power of AWS is in its managed services—DynamoDB, S3, Kinesis and Lambda. If you design your app to be \"cloud-agnostic,\" you <strong>cannot use any of them.</strong> You're forced to build on basic VMs and manage your own databases (PostgreSQL on EC2) and message queues (RabbitMQ on EC2). You've just sacrificed your biggest competitive advantage (velocity) for a false sense of security.</li>\n<li> <strong>The Talent Chasm:</strong> Finding great AWS engineers is hard enough. Finding engineers who are <em>equally</em> expert-level in AWS, GCP and Azure is finding a unicorn. 🦄 More likely, you'll have a team that is mediocre at all three.</li>\n<li> <strong>The Hidden Costs:</strong> You won't save money. You'll lose all your volume discounts and you'll be hit with a constant stream of <strong>data egress fees</strong> just to keep your data in sync between clouds. This cost alone can cripple a startup.</li>\n</ol>\n\n\n\n\n<h2>\n  \n  \n  The <em>Right</em> Answer: A Real DR Plan (Multi-Region, Not Multi-Cloud)\n</h2>\n\n<p>The problem this week wasn't that <strong>AWS failed</strong>. The problem was that <strong>a single region, <code>us-east-1</code>, failed</strong>.</p>\n\n<p>The smart, resilient and cost-effective solution for a startup is not to go multi-cloud, but to go <strong>multi-region</strong> within your primary cloud.</p>\n\n<p>This is where you must have an honest conversation about <strong>Cost vs. Availability</strong>. Your availability is a business decision, not just a technical one. Here are your options, from cheapest to most expensive:</p>\n\n<h3>\n  \n  \n  1. Cold DR: Backup &amp; Restore\n</h3>\n\n<ul>\n<li>\n<strong>How it works:</strong> You take regular backups (e.g., S3 snapshots, DynamoDB backups) and replicate them to another region using <strong>S3 Cross-Region Replication (CRR)</strong>. If a disaster happens, you manually spin up a new environment from scratch in the new region and restore from the backup.</li>\n<li>\n<strong>Cost:</strong> Very low. Just storage costs.</li>\n<li>\n<strong>Availability (RTO/RPO):</strong> Very poor. <strong>RTO</strong> (Recovery Time Objective) is in <strong>hours or days</strong>. <strong>RPO</strong> (Recovery Point Objective) is high (e.g., \"we lose the last 4 hours of data\").</li>\n<li>\n<strong>Use Case:</strong> Good for non-critical systems, dev/test environments.</li>\n</ul>\n\n<h3>\n  \n  \n  2. Warm DR: Pilot Light (The Startup Sweet Spot 💡)\n</h3>\n\n<ul>\n<li>\n<strong>How it works:</strong> This is the best balance for most startups.\n\n<ul>\n<li>\n<strong>Data:</strong> Your critical data is actively replicated to the second region. Use <strong>DynamoDB Global Tables</strong> or <strong>Aurora Global Databases</strong>.</li>\n<li>\n<strong>Infra:</strong> A <em>minimal</em> copy of your core infrastructure (e.g., your container images in ECR, a tiny app server, your IaC scripts) is \"on\" but idle in the DR region. The \"pilot light\" is lit.</li>\n<li>\n<strong>Failover:</strong> When a disaster hits, you \"turn up the gas.\" You run your scripts to scale up the app servers, promote the standby database to be the new primary and use <strong>Route 53 DNS Failover</strong> to automatically redirect all traffic.</li>\n</ul>\n\n\n</li>\n\n<li>\n\n<strong>Cost:</strong> Medium. You pay for data replication and minimal idle infrastructure.</li>\n\n<li>\n\n<strong>Availability (RTO/RPO):</strong> Good. <strong>RTO</strong> is in <strong>minutes</strong>. <strong>RPO</strong> is near-zero (you lose no data).</li>\n\n</ul>\n\n<h3>\n  \n  \n  3. Hot DR: Active-Active\n</h3>\n\n<ul>\n<li>\n<strong>How it works:</strong> You run your <em>full</em> production stack in two or more regions simultaneously. Route 53 (or a global load balancer) splits traffic between them. If one region fails, it just takes on 100% of the traffic.</li>\n<li>\n<strong>Cost:</strong> Very high. You are paying for 2x (or more) of everything.</li>\n<li>\n<strong>Availability (RTO/RPO):</strong> Excellent. <strong>RTO</strong> is in <strong>seconds</strong> (or zero). <strong>RPO</strong> is zero.</li>\n<li>\n<strong>Use Case:</strong> Only for your absolute, mission-critical, \"company-dies-if-it's-down-for-1-minute\" services.</li>\n</ul>\n\n<h2>\n  \n  \n  Your Survival Checklist\n</h2>\n\n<p>Don't wait for the next outage. As a startup, you can survive this.</p>\n\n<ol>\n<li> <strong>Move out of <code>us-east-1</code></strong> for your primary workloads. Seriously.</li>\n<li> <strong>Define your RTO/RPO.</strong> Have the business conversation: \"How long can we be down and how much data can we afford to lose?\" This dictates your budget.</li>\n<li> <strong>Implement a Pilot Light strategy</strong> for your core services.</li>\n<li> <strong>Use native replication:</strong> Use DynamoDB Global Tables, Aurora Global DBs and S3 CRR.</li>\n<li> <strong>Replicate your CI/CD assets:</strong> Make sure your container images (ECR) and deployment scripts are in your DR region, too. You can't recover if your recovery tools are in the fire.</li>\n<li> <strong>Test your plan.</strong> A DR plan you've never tested is not a plan. it's a prayer.</li>\n</ol>\n\n<p>This outage was a wake-up call. But the lesson isn't to flee AWS. It's to stop treating \"the cloud\" as one magic box and start treating a <strong>region</strong> as your true failure domain.</p>",
      "content": "<p>If you felt like half the internet was broken this week, you weren't wrong. 📉 A massive, 15-hour outage in Amazon's <code>us-east-1</code> region took down DynamoDB and with it, a huge chunk of the web.</p>\n\n<p>This wasn't just \"a server went down.\" It was a complex, cascading failure that exposed the deep interconnectedness of cloud services. For startups and scaleups, the immediate reaction is often, \"We need to be multi-cloud to prevent this!\"</p>\n\n<p>Hold on!</p>\n\n<p>The real lesson here isn't about running from your cloud provider. It's about understanding <em>what</em> failed, why <code>us-east-1</code> is a special kind of dangerous and how to build a <em>realistic</em> Disaster Recovery (DR) plan that won't bankrupt you.</p>\n\n\n\n\n<h2>\n  \n  \n  The Anatomy of a Cascading Failure\n</h2>\n\n<p>This outage was a masterclass in how modern, automated systems can fail in spectacular ways. It wasn't one thing; it was a chain of dominoes.</p>\n\n<ol>\n<li>\n<p><strong>The Trigger: A DNS Race Condition</strong><br />\nIt all started with the system that manages the DNS for DynamoDB. Think of DNS as the Internet's phonebook. This automated system had a <strong>latent race condition</strong>—a hidden bug. Two of its own processes tried to update the DynamoDB DNS record at the <em>exact same time</em>.</p>\n\n<ul>\n<li>One process (let's call it \"Slow-Worker\") grabbed an <em>old</em> plan.</li>\n<li>A second process (\"Fast-Worker\") grabbed a <em>new</em> plan and applied it successfully.</li>\n<li>\"Fast-Worker\" then did its cleanup, deleting the <em>old</em> plan that \"Slow-Worker\" was <em>still holding</em>.</li>\n<li>\"Slow-Worker\" finally woke up and applied its plan... which was now empty.</li>\n<li>\n<strong>Result:</strong> The main DNS record for <code>dynamodb.us-east-1.amazonaws.com</code> was wiped clean. All its IP addresses vanished.</li>\n</ul>\n</li>\n<li><p><strong>The First Domino: DynamoDB Goes Offline</strong><br />\nInstantly, any application (including AWS's own internal services) attempting to access DynamoDB in that region received a \"does not exist\" error. The service was unreachable.</p></li>\n<li>\n<p><strong>The Cascade: EC2, Lambda and IAM Fall Next</strong><br />\nThis is where it gets scary. Cloud services are built on top of <em>other</em> cloud services. And DynamoDB is a <strong>Tier 0 service</strong>—a foundational block.</p>\n\n<ul>\n<li>\n<strong>EC2</strong> failed because its control plane (the \"brain\" that launches new servers) uses DynamoDB to track the state and leases of its physical hardware. No DynamoDB, no new EC2 instances.</li>\n<li>\n<strong>Lambda, ECS, EKS and Fargate</strong> all failed because they all <em>run on</em> EC2. They couldn't get new computing capacity.</li>\n<li>\n<strong>Network Load Balancers</strong> started failing health checks, causing connection errors for services that were <em>technically</em> still running.</li>\n<li>\n<strong>IAM</strong>, which handles authentication, was also impacted. This is critical: during the outage, some engineers were unable to log in to the console to fix the problem.</li>\n</ul>\n</li>\n<li>\n<p><strong>The 15-Hour Recovery and \"Congestive Collapse\"</strong><br />\nEngineers fixed the DNS record relatively quickly, but the outage lasted 15 hours. Why?</p>\n\n<ul>\n<li>\n<strong>DNS Caching:</strong> The \"empty\" (and wrong) DNS record was cached by resolvers all over the internet. They had to wait for that cache to expire.</li>\n<li>\n<strong>Congestive Collapse:</strong> When the service finally came back, a \"thundering herd\" of <em>every single service</em> retrying at once hammered DynamoDB. The system, in its weakened recovery state, was so overwhelmed by recovery work that it couldn't make forward progress. Engineers had to manually throttle traffic and drain backlogs to bring it back online safely.</li>\n</ul>\n</li>\n</ol>\n\n\n\n\n<h2>\n  \n  \n  The Global Blast Radius: Why You Should <em>Never</em> Host in <code>us-east-1</code>\n</h2>\n\n<p>\"But I don't even use <code>us-east-1</code>!\" you might say. \"I'm in <code>eu-west-3</code> (Paris)!\"</p>\n\n<p>It didn't matter. This outage had a global impact and it exposes the dirty secret of AWS: <strong><code>us-east-1</code> (N. Virginia) is not just another region.</strong></p>\n\n<p>Because it's the <em>oldest</em> AWS region, many \"global\" services have their control planes homed there by default.</p>\n\n<ul>\n<li>\n<strong>Global IAM Console:</strong> The main IAM dashboard and API are, by default, in <code>us-east-1</code>. During the outage, users in other regions reported being unable to manage permissions or roles.</li>\n<li>\n<strong>S3 Management Console:</strong> The \"global\" S3 console is also hosted there. You could still <em>access</em> your data in a bucket in Frankfurt, but you couldn't <em>manage</em> the bucket (e.g., change policies, create new buckets).</li>\n<li>\n<strong>Global Services:</strong> Services like DynamoDB Global Tables, which replicate data worldwide, saw massive replication lag to and from the failed region.</li>\n</ul>\n\n\n\n\n<h2>\n  \n  \n  The Multi-Cloud Fallacy: Doubling Your Problems, Not Your Uptime\n</h2>\n\n<p>When an event like this happens, the C-suite's first question is, \"Why aren't we on GCP and Azure, too?\"</p>\n\n<p>For a startup or scaleup, \"multi-cloud\" is a trap. It's a strategy for massive, risk-averse banks and Fortune 100s with regulatory requirements, not for a company that needs to move fast.</p>\n\n<p>Chasing multi-cloud to solve for availability is a terrible trade-off. Here’s why:</p>\n\n<ol>\n<li> <strong>Exponential Complexity:</strong> You think AWS IAM is hard? Now try to manage AWS IAM, Google Cloud IAM and Azure Entra ID and make them all talk to each other securely. Your 3-person DevOps team is now responsible for three entirely different networking stacks, security models and deployment pipelines.</li>\n<li> <strong>The \"Lowest Common Denominator\" Problem:</strong> This is the <em>killer</em>. The real power of AWS is in its managed services—DynamoDB, S3, Kinesis and Lambda. If you design your app to be \"cloud-agnostic,\" you <strong>cannot use any of them.</strong> You're forced to build on basic VMs and manage your own databases (PostgreSQL on EC2) and message queues (RabbitMQ on EC2). You've just sacrificed your biggest competitive advantage (velocity) for a false sense of security.</li>\n<li> <strong>The Talent Chasm:</strong> Finding great AWS engineers is hard enough. Finding engineers who are <em>equally</em> expert-level in AWS, GCP and Azure is finding a unicorn. 🦄 More likely, you'll have a team that is mediocre at all three.</li>\n<li> <strong>The Hidden Costs:</strong> You won't save money. You'll lose all your volume discounts and you'll be hit with a constant stream of <strong>data egress fees</strong> just to keep your data in sync between clouds. This cost alone can cripple a startup.</li>\n</ol>\n\n\n\n\n<h2>\n  \n  \n  The <em>Right</em> Answer: A Real DR Plan (Multi-Region, Not Multi-Cloud)\n</h2>\n\n<p>The problem this week wasn't that <strong>AWS failed</strong>. The problem was that <strong>a single region, <code>us-east-1</code>, failed</strong>.</p>\n\n<p>The smart, resilient and cost-effective solution for a startup is not to go multi-cloud, but to go <strong>multi-region</strong> within your primary cloud.</p>\n\n<p>This is where you must have an honest conversation about <strong>Cost vs. Availability</strong>. Your availability is a business decision, not just a technical one. Here are your options, from cheapest to most expensive:</p>\n\n<h3>\n  \n  \n  1. Cold DR: Backup &amp; Restore\n</h3>\n\n<ul>\n<li>\n<strong>How it works:</strong> You take regular backups (e.g., S3 snapshots, DynamoDB backups) and replicate them to another region using <strong>S3 Cross-Region Replication (CRR)</strong>. If a disaster happens, you manually spin up a new environment from scratch in the new region and restore from the backup.</li>\n<li>\n<strong>Cost:</strong> Very low. Just storage costs.</li>\n<li>\n<strong>Availability (RTO/RPO):</strong> Very poor. <strong>RTO</strong> (Recovery Time Objective) is in <strong>hours or days</strong>. <strong>RPO</strong> (Recovery Point Objective) is high (e.g., \"we lose the last 4 hours of data\").</li>\n<li>\n<strong>Use Case:</strong> Good for non-critical systems, dev/test environments.</li>\n</ul>\n\n<h3>\n  \n  \n  2. Warm DR: Pilot Light (The Startup Sweet Spot 💡)\n</h3>\n\n<ul>\n<li>\n<strong>How it works:</strong> This is the best balance for most startups.\n\n<ul>\n<li>\n<strong>Data:</strong> Your critical data is actively replicated to the second region. Use <strong>DynamoDB Global Tables</strong> or <strong>Aurora Global Databases</strong>.</li>\n<li>\n<strong>Infra:</strong> A <em>minimal</em> copy of your core infrastructure (e.g., your container images in ECR, a tiny app server, your IaC scripts) is \"on\" but idle in the DR region. The \"pilot light\" is lit.</li>\n<li>\n<strong>Failover:</strong> When a disaster hits, you \"turn up the gas.\" You run your scripts to scale up the app servers, promote the standby database to be the new primary and use <strong>Route 53 DNS Failover</strong> to automatically redirect all traffic.</li>\n</ul>\n\n\n</li>\n\n<li>\n\n<strong>Cost:</strong> Medium. You pay for data replication and minimal idle infrastructure.</li>\n\n<li>\n\n<strong>Availability (RTO/RPO):</strong> Good. <strong>RTO</strong> is in <strong>minutes</strong>. <strong>RPO</strong> is near-zero (you lose no data).</li>\n\n</ul>\n\n<h3>\n  \n  \n  3. Hot DR: Active-Active\n</h3>\n\n<ul>\n<li>\n<strong>How it works:</strong> You run your <em>full</em> production stack in two or more regions simultaneously. Route 53 (or a global load balancer) splits traffic between them. If one region fails, it just takes on 100% of the traffic.</li>\n<li>\n<strong>Cost:</strong> Very high. You are paying for 2x (or more) of everything.</li>\n<li>\n<strong>Availability (RTO/RPO):</strong> Excellent. <strong>RTO</strong> is in <strong>seconds</strong> (or zero). <strong>RPO</strong> is zero.</li>\n<li>\n<strong>Use Case:</strong> Only for your absolute, mission-critical, \"company-dies-if-it's-down-for-1-minute\" services.</li>\n</ul>\n\n<h2>\n  \n  \n  Your Survival Checklist\n</h2>\n\n<p>Don't wait for the next outage. As a startup, you can survive this.</p>\n\n<ol>\n<li> <strong>Move out of <code>us-east-1</code></strong> for your primary workloads. Seriously.</li>\n<li> <strong>Define your RTO/RPO.</strong> Have the business conversation: \"How long can we be down and how much data can we afford to lose?\" This dictates your budget.</li>\n<li> <strong>Implement a Pilot Light strategy</strong> for your core services.</li>\n<li> <strong>Use native replication:</strong> Use DynamoDB Global Tables, Aurora Global DBs and S3 CRR.</li>\n<li> <strong>Replicate your CI/CD assets:</strong> Make sure your container images (ECR) and deployment scripts are in your DR region, too. You can't recover if your recovery tools are in the fire.</li>\n<li> <strong>Test your plan.</strong> A DR plan you've never tested is not a plan. it's a prayer.</li>\n</ol>\n\n<p>This outage was a wake-up call. But the lesson isn't to flee AWS. It's to stop treating \"the cloud\" as one magic box and start treating a <strong>region</strong> as your true failure domain.</p>",
      "url": "https://dev.to/aws-builders/dynamodb-outage-why-multi-cloud-fails-startups-and-real-dr-wins-15cb",
      "image": "",
      "publishedAt": "Fri, 24 Oct 2025 13:42:38 +0000",
      "lang": "en",
      "source": {
        "id": "dev.to",
        "name": "Dev.to",
        "url": "https://dev.to/feed",
        "country": ""
      }
    }
  },
  {
    "source": "The Hacker News",
    "url": "https://feeds.feedburner.com/TheHackersNews",
    "coverage": 88.9,
    "example": {
      "id": 9057707166,
      "title": "The Cybersecurity Perception Gap: Why Executives and Practitioners See Risk Differently",
      "description": "Does your organization suffer from a cybersecurity perception gap? Findings from the&nbsp;Bitdefender 2025 Cybersecurity Assessment suggest the answer is probably “yes” — and many leaders may not even realize it.\nThis disconnect matters. Small differences in perception today can evolve into major blind spots tomorrow. After all, perception influences what organizations prioritize, where they",
      "content": "Does your organization suffer from a cybersecurity perception gap? Findings from the&nbsp;Bitdefender 2025 Cybersecurity Assessment suggest the answer is probably “yes” — and many leaders may not even realize it.\nThis disconnect matters. Small differences in perception today can evolve into major blind spots tomorrow. After all, perception influences what organizations prioritize, where they",
      "url": "https://thehackernews.com/2025/10/the-cybersecurity-perception-gap-why.html",
      "image": "",
      "publishedAt": "Fri, 24 Oct 2025 16:30:00 +0530",
      "lang": "en",
      "source": {
        "id": "feeds.feedburner.com",
        "name": "The Hacker News",
        "url": "https://feeds.feedburner.com/TheHackersNews",
        "country": ""
      }
    }
  }
]